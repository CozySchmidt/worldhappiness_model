{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> World Happiness Index Model </h1>"
   ]
  },
  {
   "attachments": {
    "happy.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![happy.jpg](attachment:happy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>In this notebook I will be going over the dataset of the World Happiness Index of 2019 to try and determine specific factors that correlate to a high happiness index. </h2> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <u>Problem Definition</u> </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> I am trying to find which factors have the highest correlation to a high happiness score. <br>Obviously, if a category like \"Healthy Life Expectancy\" has a low value then that will have a bad correlation to the happiness score. <br>But what I am most interested in though is which column with a high value will still have a bad correlation to the happiness score.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <u>Exploratory Data Analysis</u> </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Here are the different features that make up the dataset that I am using. I will also drop the Country or region column with the country names and the overall rank column because it won't add anything to help the model.</h3>\n",
    "\n",
    "\n",
    "<h3> I will be using the \"Score\" feature as my predictor variable. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.769</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.600</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.554</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.494</td>\n",
       "      <td>1.380</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.488</td>\n",
       "      <td>1.396</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score  GDP per capita  Social support  Healthy life expectancy  \\\n",
       "0  7.769           1.340           1.587                    0.986   \n",
       "1  7.600           1.383           1.573                    0.996   \n",
       "2  7.554           1.488           1.582                    1.028   \n",
       "3  7.494           1.380           1.624                    1.026   \n",
       "4  7.488           1.396           1.522                    0.999   \n",
       "\n",
       "   Freedom to make life choices  Generosity  Perceptions of corruption  \n",
       "0                         0.596       0.153                      0.393  \n",
       "1                         0.592       0.252                      0.410  \n",
       "2                         0.603       0.271                      0.341  \n",
       "3                         0.591       0.354                      0.118  \n",
       "4                         0.557       0.322                      0.298  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('WorldHappinessIndex2019.csv', delimiter=\",\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Shown below is the overall description of the entire dataset. <br><br> As you can see the standard deviations of each column are relatively small. Also, the overall mean of the 'Score' column is 5, with the #1 country being at 7.769 so the mean of the world happiness score isn't too bad. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.407096</td>\n",
       "      <td>0.905147</td>\n",
       "      <td>1.208814</td>\n",
       "      <td>0.725244</td>\n",
       "      <td>0.392571</td>\n",
       "      <td>0.184846</td>\n",
       "      <td>0.110603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.113120</td>\n",
       "      <td>0.398389</td>\n",
       "      <td>0.299191</td>\n",
       "      <td>0.242124</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.095254</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.853000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.544500</td>\n",
       "      <td>0.602750</td>\n",
       "      <td>1.055750</td>\n",
       "      <td>0.547750</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.108750</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.379500</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.271500</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.184500</td>\n",
       "      <td>1.232500</td>\n",
       "      <td>1.452500</td>\n",
       "      <td>0.881750</td>\n",
       "      <td>0.507250</td>\n",
       "      <td>0.248250</td>\n",
       "      <td>0.141250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.769000</td>\n",
       "      <td>1.684000</td>\n",
       "      <td>1.624000</td>\n",
       "      <td>1.141000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.453000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Score GDP per capita Social support Healthy life expectancy  \\\n",
       "count  156.000000     156.000000     156.000000              156.000000   \n",
       "mean     5.407096       0.905147       1.208814                0.725244   \n",
       "std      1.113120       0.398389       0.299191                0.242124   \n",
       "min      2.853000       0.000000       0.000000                0.000000   \n",
       "25%      4.544500       0.602750       1.055750                0.547750   \n",
       "50%      5.379500       0.960000       1.271500                0.789000   \n",
       "75%      6.184500       1.232500       1.452500                0.881750   \n",
       "max      7.769000       1.684000       1.624000                1.141000   \n",
       "\n",
       "      Freedom to make life choices  Generosity Perceptions of corruption  \n",
       "count                   156.000000  156.000000                156.000000  \n",
       "mean                      0.392571    0.184846                  0.110603  \n",
       "std                       0.143289    0.095254                  0.094538  \n",
       "min                       0.000000    0.000000                  0.000000  \n",
       "25%                       0.308000    0.108750                  0.047000  \n",
       "50%                       0.417000    0.177500                  0.085500  \n",
       "75%                       0.507250    0.248250                  0.141250  \n",
       "max                       0.631000    0.566000                  0.453000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> You can also see that there are a couple columns that have a minimum value of 0 which we dont want, so we will impute based on the average of the values above and below the 0.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Below is where I impute the data and then if we call the same function used above, it will show that there are no more 0 values. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This replaces all zeroes with nan\n",
    "\n",
    "import numpy as np\n",
    "df[df.eq(0)] = np.nan\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "df = pd.DataFrame(imputer.fit_transform(df))\n",
    "\n",
    "df.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))\n",
    "df.columns = ['Score','GDP per capita','Social support', 'Healthy life expectancy'\n",
    "              , 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u>Feature Segmentation</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  GDP per capita  Social support  Healthy life expectancy  Freedom to make life choices  Generosity  Perceptions of corruption\n",
      "0  7.769           1.340           1.587                    0.986                         0.596       0.153                      0.393\n",
      "1  7.600           1.383           1.573                    0.996                         0.592       0.252                      0.410\n",
      "\n",
      "Bartlett's test chi-square value: \n",
      "679.3983260724755\n",
      "\n",
      "Bartlett's test p-value: \n",
      "2.977623700823043e-130\n",
      "\n",
      "Kaiser-Meyer-Olkin (KMO) Test\n",
      "0.8340585223845253\n",
      "\n",
      "Eignenvalues:\n",
      "[3.82509495 1.41951341 0.61521633 0.56875235 0.25842885 0.17118771\n",
      " 0.14180641]\n",
      "\n",
      "Factors: \n",
      "   Factor 1  Factor 2                    Categories\n",
      "0  0.868441  0.319160                         Score\n",
      "1  0.915752  0.068961                GDP per capita\n",
      "2  0.835244  0.073839                Social support\n",
      "3  0.885019  0.099383       Healthy life expectancy\n",
      "4  0.411562  0.553433  Freedom to make life choices\n",
      "5 -0.115293  0.564996                    Generosity\n",
      "6  0.241607  0.609551     Perceptions of corruption\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pip install factor-analyzer\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "# # Create data frame without ID and target variable columns.\n",
    "\n",
    "# del df['Satisfaction']\n",
    "\n",
    "# Display all columns of the data frame.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df.head(2))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Bartlett's test of sphericity checks for enough correlation.\n",
    "# A small p-value indicates that enough correlation exists.\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value, p_value=calculate_bartlett_sphericity(df)\n",
    "\n",
    "print(\"\\nBartlett's test chi-square value: \")\n",
    "print(chi_square_value)\n",
    "\n",
    "print(\"\\nBartlett's test p-value: \")\n",
    "print(p_value)\n",
    "\n",
    "# Kaiser-Meyer-Olkin (KMO) test checks for common variance.\n",
    "# Factor analysis is suitable for scores of 0.6 (and\n",
    "# sometimes 0.5) and above.\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(df)\n",
    "print(\"\\nKaiser-Meyer-Olkin (KMO) Test\")\n",
    "print(kmo_model)\n",
    "\n",
    "# Create components loading vectors without rotation\n",
    "# and obtain the Eigenvalues.\n",
    "fa = FactorAnalyzer(rotation=None)\n",
    "fa.fit(df)\n",
    "\n",
    "ev, v = fa.get_eigenvalues()\n",
    "print(\"\\nEignenvalues:\")\n",
    "print(ev)\n",
    "\n",
    "# Pick factors where eigenvalues are greater than 1.\n",
    "fa = FactorAnalyzer(rotation=\"varimax\",n_factors=2)\n",
    "fa.fit(df)\n",
    "\n",
    "# Create formatted factor loading matrix.\n",
    "dfFactors = pd.DataFrame(fa.loadings_)\n",
    "dfFactors['Categories'] = list(df.keys())\n",
    "dfFactors = dfFactors.rename(columns={0:'Factor 1',\n",
    "          1:'Factor 2', 2:'Factor 3', 3:'Factor 4'})\n",
    "print(\"\\nFactors: \")\n",
    "print(dfFactors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The features that influence the first factor are a good GDP per capita, Social support, and Healthy life expectancy. This could be an indicator that companies with good social programs correlate to a good happiness score. <br><br> For the second factor, the features that are most relevant are Freedom to make life choices, Generosity, and Perceptions of corruption. This could be a good indicator that first world countries that prioritize democracy and safety of their citizens correlate to a good happiness score. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2><u>Data Treatment</u></h2>\n",
    "<h3>I initially dropped the first two columns which are the index and the name of the country, since I don't think they would have any influence on the model. <br> Also, some columns had a 0 as the minimum value, which I did not want in my model because it would wrongly lower the average. <br> So I used the KNN Imputer to get the average of the 4 neighbors around the 0 value. I also used binning to see if there was a specific range of values that helped the RMSE value. <br> The ranges that I determined were the most helpful are GDPBin_(0.912, 1.684], SocialBin_(1.2, 1.624]. Considering the original columns had significant p-values, it makes sense that only the binning for these two columns had the best results.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now I am going to run an OLS model to find the bad features then bin the good features and run the OLS model again.  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.799\n",
      "Model:                            OLS   Adj. R-squared:                  0.793\n",
      "Method:                 Least Squares   F-statistic:                     118.5\n",
      "Date:                Sat, 09 Apr 2022   Prob (F-statistic):           1.56e-40\n",
      "Time:                        15:50:02   Log-Likelihood:                -89.887\n",
      "No. Observations:                 124   AIC:                             189.8\n",
      "Df Residuals:                     119   BIC:                             203.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.9787      0.213      9.300      0.000       1.557       2.400\n",
      "x1             1.1791      0.184      6.415      0.000       0.815       1.543\n",
      "x2             1.3127      0.258      5.095      0.000       0.803       1.823\n",
      "x3             1.6400      0.392      4.181      0.000       0.863       2.417\n",
      "x4             1.4667      0.582      2.519      0.013       0.314       2.620\n",
      "==============================================================================\n",
      "Omnibus:                        2.614   Durbin-Watson:                   1.896\n",
      "Prob(Omnibus):                  0.271   Jarque-Bera (JB):                2.244\n",
      "Skew:                          -0.325   Prob(JB):                        0.326\n",
      "Kurtosis:                       3.104   Cond. No.                         25.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Root Mean Squared Error: 0.6708532385003275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api       as sm\n",
    "\n",
    "X = df[['GDP per capita', 'Social support', 'Freedom to make life choices', 'Perceptions of corruption']].values\n",
    "\n",
    "# Adding an intercept *** This is required ***. Don't forget this step.\n",
    "# The intercept centers the error residuals around zero\n",
    "# which helps to avoid over-fitting.\n",
    "X = sm.add_constant(X)\n",
    "y = df['Score'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_test) # make the predictions by the model\n",
    "print(model.summary())\n",
    "print('Root Mean Squared Error:',\n",
    "      np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Shown in the model summary is that there are a couple of features that don't provide any good insight into our prediction so we can drop those features and then also bin the good categories to see if that will have a positive effect on the RMSE. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GDPBin'] = pd.cut(x=df['GDP per capita'], bins=[0,0.3,0.71,0.912, 1.684])\n",
    "df['SocialBin'] = pd.cut(x=df['Social support'], bins=[0,0.572,1.2,1.624])\n",
    "\n",
    "tempDf = df[['GDPBin','SocialBin']]\n",
    "\n",
    "dummyDf = pd.get_dummies(tempDf, columns=['GDPBin','SocialBin'])\n",
    "\n",
    "df = pd.concat(([df, dummyDf]),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.754\n",
      "Model:                            OLS   Adj. R-squared:                  0.737\n",
      "Method:                 Least Squares   F-statistic:                     44.14\n",
      "Date:                Sat, 09 Apr 2022   Prob (F-statistic):           1.35e-31\n",
      "Time:                        15:50:10   Log-Likelihood:                -102.42\n",
      "No. Observations:                 124   AIC:                             222.8\n",
      "Df Residuals:                     115   BIC:                             248.2\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.0885      0.464      6.659      0.000       2.170       4.007\n",
      "x1             1.9517      0.447      4.366      0.000       1.066       2.837\n",
      "x2             2.5438      0.648      3.924      0.000       1.260       3.828\n",
      "x3            -0.7209      0.622     -1.159      0.249      -1.953       0.511\n",
      "x4            -0.3896      0.600     -0.649      0.518      -1.579       0.800\n",
      "x5            -0.3886      0.601     -0.646      0.519      -1.580       0.803\n",
      "x6             0.1873      0.581      0.322      0.748      -0.963       1.338\n",
      "x7             0.4309      0.261      1.651      0.101      -0.086       0.948\n",
      "x8             0.8801      0.181      4.859      0.000       0.521       1.239\n",
      "x9             1.7775      0.193      9.228      0.000       1.396       2.159\n",
      "==============================================================================\n",
      "Omnibus:                       22.758   Durbin-Watson:                   2.074\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.068\n",
      "Skew:                          -0.845   Prob(JB):                     5.42e-09\n",
      "Kurtosis:                       5.125   Cond. No.                     1.94e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.98e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Root Mean Squared Error: 0.6566358878823629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api       as sm\n",
    "\n",
    "\n",
    "\n",
    "X = df[['Freedom to make life choices','Perceptions of corruption','GDPBin_(0.0, 0.3]',\n",
    "        'GDPBin_(0.3, 0.71]','GDPBin_(0.71, 0.912]','GDPBin_(0.912, 1.684]','SocialBin_(0.0, 0.572]','SocialBin_(0.572, 1.2]',\n",
    "        'SocialBin_(1.2, 1.624]']].values\n",
    "\n",
    "# Adding an intercept *** This is required ***. Don't forget this step.\n",
    "# The intercept centers the error residuals around zero\n",
    "# which helps to avoid over-fitting.\n",
    "X = sm.add_constant(X)\n",
    "y = df['Score'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_test) # make the predictions by the model\n",
    "print(model.summary())\n",
    "print('Root Mean Squared Error:',\n",
    "      np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> With a bit of binning, you can already see the RMSE value drop by .02 points. Now let's drop the bad features and see if the RMSE improves at all. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.740\n",
      "Model:                            OLS   Adj. R-squared:                  0.731\n",
      "Method:                 Least Squares   F-statistic:                     84.71\n",
      "Date:                Sat, 09 Apr 2022   Prob (F-statistic):           6.84e-34\n",
      "Time:                        15:50:19   Log-Likelihood:                -105.90\n",
      "No. Observations:                 124   AIC:                             221.8\n",
      "Df Residuals:                     119   BIC:                             235.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.4120      0.151     22.647      0.000       3.114       3.710\n",
      "x1             2.1086      0.443      4.756      0.000       1.231       2.986\n",
      "x2             2.4640      0.649      3.796      0.000       1.179       3.749\n",
      "x3             0.6282      0.133      4.735      0.000       0.366       0.891\n",
      "x4             0.9693      0.144      6.749      0.000       0.685       1.254\n",
      "==============================================================================\n",
      "Omnibus:                       16.192   Durbin-Watson:                   2.040\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.643\n",
      "Skew:                          -0.706   Prob(JB):                     2.00e-05\n",
      "Kurtosis:                       4.481   Cond. No.                         18.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Root Mean Squared Error: 0.6322271851219121\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api       as sm\n",
    "\n",
    "\n",
    "\n",
    "X = df[['Freedom to make life choices','Perceptions of corruption',\n",
    "        'GDPBin_(0.912, 1.684]',\n",
    "        'SocialBin_(1.2, 1.624]']].values\n",
    "\n",
    "# Adding an intercept *** This is required ***. Don't forget this step.\n",
    "# The intercept centers the error residuals around zero\n",
    "# which helps to avoid over-fitting.\n",
    "X = sm.add_constant(X)\n",
    "y = df['Score'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_test) # make the predictions by the model\n",
    "print(model.summary())\n",
    "print('Root Mean Squared Error:',\n",
    "      np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>After dropping the bad binned features, the RMSE on the model drops another .02. That's not bad for just a little bit of binning. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The conclusion is that the features that are the most relevant are 'Freedom to make life choices' and 'Perceptions of corruption' while the values of GDP per capita give best results between 0.912 and 1.684, also the values of Social support give the best result between 1.2 and 1.624 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now let's look at making a neural net and see if the RMSE value improves at all. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We first have to find what the baseline RMSE value is of a neural network. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn                 import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models            import Sequential\n",
    "from keras.layers            import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('WorldHappinessIndex2019.csv', delimiter=\",\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "df[df.eq(0)] = np.nan\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "df = pd.DataFrame(imputer.fit_transform(df))\n",
    "\n",
    "df.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))\n",
    "df.columns = ['Score','GDP per capita','Social support', 'Healthy life expectancy'\n",
    "              , 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 30.4592\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 29.8264\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 28.8374\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 27.3893\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 25.5405\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 907us/step - loss: 23.3208\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 20.8533\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 18.1685\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 15.4558\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 12.7746\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 10.2609\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 726us/step - loss: 7.9325\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 5.9521\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 4.3144\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 3.0054\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 2.0337\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 618us/step - loss: 1.3487\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.9006\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.6183\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.4563\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3611\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3115\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2841\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2729\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 0.2659\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2640\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2630\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 727us/step - loss: 0.2627\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2623\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2623\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2620\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2618\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2622\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2616\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 660us/step - loss: 0.2618\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2615\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2608\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2612\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2608\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2608\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2603\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2603\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2600\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2618\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.2598\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2594\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2605\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2592\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2588\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2613\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2585\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2583\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2585\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2579\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2578\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2582\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2584\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 643us/step - loss: 0.2574\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2577\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2574\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2573\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2570\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2566\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2569\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2561\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2558\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2561\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2561\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2564\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2550\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2549\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2550\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2547\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2547\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2546\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2538\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2555\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2531\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2538\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2540\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2531\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2534\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2532\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2527\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2524\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2526\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2573\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2505\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2533\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2533\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2526\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2514\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2513\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2509\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2536\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2526\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2532\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 683us/step - loss: 0.2506\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 679us/step - loss: 0.2506\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2502\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.4025\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 30.2922\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 29.6162\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 997us/step - loss: 28.5964\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 27.1709\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 606us/step - loss: 25.3701\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 677us/step - loss: 23.2155\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 20.7577\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 18.1200\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 15.3865\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 12.7410\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 629us/step - loss: 10.2329\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 7.9916\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 5.9736\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 4.3632\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 3.0844\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 545us/step - loss: 2.1218\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 544us/step - loss: 1.4397\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.9780\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 588us/step - loss: 0.6683\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.4841\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3794\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.3207\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2939\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 618us/step - loss: 0.2802\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2722\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2679\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2662\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2647\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 664us/step - loss: 0.2639\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 637us/step - loss: 0.2634\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2631\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 707us/step - loss: 0.2629\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2625\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 671us/step - loss: 0.2624\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2621\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 632us/step - loss: 0.2614\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2617\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2614\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2612\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2614\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 649us/step - loss: 0.2608\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2610\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2605\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2608\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2598\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2603\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2597\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 632us/step - loss: 0.2593\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2603\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2586\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2587\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2589\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2582\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2581\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 620us/step - loss: 0.2577\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2577\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2573\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2570\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2567\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2569\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2563\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2563\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 631us/step - loss: 0.2560\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2560\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2555\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2560\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2553\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2579\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 648us/step - loss: 0.2553\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2548\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2546\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2543\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2541\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2537\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2539\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2535\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2533\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2528\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 665us/step - loss: 0.2529\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2532\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2533\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2519\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2528\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2524\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2525\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2515\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2512\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2506\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2513\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2530\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2517\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2499\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2502\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2500\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2498\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2499\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 635us/step - loss: 0.2497\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2497\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 652us/step - loss: 0.2492\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 650us/step - loss: 0.2493\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.3763\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 31.0384\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 30.5477\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 29.8879\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 627us/step - loss: 29.0273\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 27.9345\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 655us/step - loss: 26.6174\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 25.1115\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 23.4497\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 21.6375\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 19.7520\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 17.8095\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 15.8666\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 13.9082\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 12.0195\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 659us/step - loss: 10.2302\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 8.5936\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 7.0763\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 5.7524\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 4.6133\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 3.6228\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 2.8256\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 641us/step - loss: 2.1562\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 661us/step - loss: 1.6429\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 1.2513\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.9417\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.7243\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.5756\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 632us/step - loss: 0.4658\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3959\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3477\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3156\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 627us/step - loss: 0.2954\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2842\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2762\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2719\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2691\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2687\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 726us/step - loss: 0.2671\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 625us/step - loss: 0.2669\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2668\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2671\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2664\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2662\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2664\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2663\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 672us/step - loss: 0.2666\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2661\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2660\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.2670\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2665\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2660\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2659\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.2660\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2661\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2658\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2658\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2658\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2663\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2660\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2655\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 544us/step - loss: 0.2654\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2656\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 576us/step - loss: 0.2668\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2653\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2655\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2659\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 795us/step - loss: 0.2652\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 673us/step - loss: 0.2665\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2655\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2651\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2656\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2650\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2651\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 588us/step - loss: 0.2649\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2664\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2648\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2659\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 624us/step - loss: 0.2658\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2649\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 726us/step - loss: 0.2647\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2645\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2648\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2653\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 588us/step - loss: 0.2651\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2644\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2645\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2643\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2647\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2643\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2644\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2639\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2648\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2639\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2642\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 0.2637\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2636\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2635\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2634\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2652\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.2826\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 29.8743\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 29.5489\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 786us/step - loss: 29.1321\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 627us/step - loss: 28.5998\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 27.9515\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 27.1988\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 26.3193\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 25.3542\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 24.2957\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 23.1477\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 21.9404\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 613us/step - loss: 20.6741\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 630us/step - loss: 19.3935\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 18.0684\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 16.7139\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 15.3477\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 14.0372\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 620us/step - loss: 12.7462\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 11.5036\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 544us/step - loss: 10.3012\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 9.1504\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 587us/step - loss: 8.0708\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 7.0726\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 6.1708\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 5.3165\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 588us/step - loss: 4.5556\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 3.8884\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 628us/step - loss: 3.2734\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 769us/step - loss: 2.7424\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 2.2737\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 1.8873\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 1.5547\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 1.2908\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 615us/step - loss: 1.0728\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.8910\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.7513\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.6340\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.5430\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.4774\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.4266\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.3865\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3566\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3358\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3190\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3095\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2983\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2932\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2895\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2870\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2860\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2839\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2834\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2832\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2829\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2827\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2829\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2828\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2825\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2824\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2824\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2821\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2826\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2822\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2822\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2822\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2828\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2823\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.2821\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2820\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 727us/step - loss: 0.2821\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2819\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2825\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2822\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2821\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2825\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2822\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2822\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 0.2816\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2822\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.2833\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2835\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2836\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2821\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2816\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2819\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2817\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2814\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2818\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2815\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2816\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2815\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 635us/step - loss: 0.2819\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2815\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2815\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2820\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2816\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2816\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2817\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2816\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2820\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0699\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 30.3383\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 30.0041\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 29.5778\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 670us/step - loss: 29.0331\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 644us/step - loss: 28.3751\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 664us/step - loss: 27.5924\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 26.6923\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 25.6917\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 689us/step - loss: 24.5979\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 23.4223\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 22.1902\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 20.9154\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 19.5707\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 18.2148\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 723us/step - loss: 16.8572\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 626us/step - loss: 15.4973\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 692us/step - loss: 14.1701\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 12.8423\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 11.5725\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 10.3329\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 663us/step - loss: 9.1887\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 8.0927\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 7.0847\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 6.1335\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 622us/step - loss: 5.2725\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 4.5070\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 703us/step - loss: 3.8238\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 3.2130\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 2.6920\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 2.2396\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 1.8554\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 673us/step - loss: 1.5327\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 1.2598\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 1.0352\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.8568\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.7136\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.6015\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 711us/step - loss: 0.5157\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.4480\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3969\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.3569\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3296\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3089\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2945\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2843\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2776\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2735\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2699\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 655us/step - loss: 0.2675\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2658\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2643\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2635\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 599us/step - loss: 0.2633\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2630\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2623\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2621\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2619\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2619\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2617\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2622\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2627\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2619\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2623\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2620\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2619\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2615\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2616\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2616\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2618\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2616\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2615\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2616\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2616\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2614\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2621\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 772us/step - loss: 0.2612\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2618\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2614\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2614\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2615\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2616\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2612\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2618\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2611\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2612\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2613\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2619\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2612\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.2612\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 658us/step - loss: 0.2612\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2610\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2612\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2612\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2613\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2615\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2612\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 643us/step - loss: 0.2611\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2614\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 651us/step - loss: 0.2611\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2785\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 665us/step - loss: 29.8229\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 29.3785\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 28.7577\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 579us/step - loss: 27.9302\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 26.8905\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 25.6267\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 677us/step - loss: 24.1640\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 661us/step - loss: 22.5526\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 20.7703\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 18.9503\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 17.0314\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 15.1588\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 13.2347\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 11.4184\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 9.7058\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 577us/step - loss: 8.1546\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 6.7122\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 5.4588\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 4.3398\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 622us/step - loss: 3.4195\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 2.6598\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 2.0354\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 1.5482\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 1.1772\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.9029\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.6966\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.5503\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.4525\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.3825\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 654us/step - loss: 0.3402\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 641us/step - loss: 0.3107\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2921\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 641us/step - loss: 0.2824\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2751\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2711\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2690\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2679\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2669\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2666\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 706us/step - loss: 0.2665\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2666\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2663\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 649us/step - loss: 0.2661\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2665\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2659\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 688us/step - loss: 0.2659\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2660\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2660\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 628us/step - loss: 0.2656\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 625us/step - loss: 0.2657\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 619us/step - loss: 0.2656\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2655\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 586us/step - loss: 0.2655\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2660\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2657\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 699us/step - loss: 0.2652\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 0.2652\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2655\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 720us/step - loss: 0.2654\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2654\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2651\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2650\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2647\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2651\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2644\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2648\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 727us/step - loss: 0.2645\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 0.2644\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2643\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2646\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2649\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2640\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2641\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2639\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2641\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2645\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2645\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2641\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 631us/step - loss: 0.2636\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2635\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2637\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2631\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2632\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2634\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 649us/step - loss: 0.2630\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 698us/step - loss: 0.2631\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 673us/step - loss: 0.2634\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2628\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 726us/step - loss: 0.2653\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 698us/step - loss: 0.2625\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 626us/step - loss: 0.2628\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2628\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 659us/step - loss: 0.2626\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 658us/step - loss: 0.2623\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2624\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 626us/step - loss: 0.2622\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 0.2623\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2627\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2623\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 650us/step - loss: 0.2621\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3092\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 676us/step - loss: 29.8409\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 29.5038\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 676us/step - loss: 28.9971\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 28.2164\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 26.9796\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 667us/step - loss: 25.3249\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 23.3079\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 674us/step - loss: 21.0445\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 18.6442\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 652us/step - loss: 16.1583\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 13.7210\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 11.3956\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 9.2223\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 707us/step - loss: 7.3092\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 5.6349\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 705us/step - loss: 4.2392\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 3.0985\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 693us/step - loss: 2.2252\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 1.5630\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 625us/step - loss: 1.0995\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 670us/step - loss: 0.7866\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 706us/step - loss: 0.5758\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.4523\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.3699\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 669us/step - loss: 0.3271\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3013\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2869\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2792\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2757\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2739\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2733\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2728\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2736\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2727\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 654us/step - loss: 0.2725\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 704us/step - loss: 0.2720\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2722\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2721\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2718\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 693us/step - loss: 0.2719\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 0.2714\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2711\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2712\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 623us/step - loss: 0.2706\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2710\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 695us/step - loss: 0.2711\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2710\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 655us/step - loss: 0.2704\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.2701\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 667us/step - loss: 0.2701\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2710\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2698\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2693\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 594us/step - loss: 0.2693\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 625us/step - loss: 0.2695\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 642us/step - loss: 0.2689\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 726us/step - loss: 0.2683\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 649us/step - loss: 0.2683\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 608us/step - loss: 0.2685\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 612us/step - loss: 0.2688\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2687\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 592us/step - loss: 0.2679\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 623us/step - loss: 0.2675\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2673\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 668us/step - loss: 0.2674\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2674\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2671\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 721us/step - loss: 0.2665\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2668\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 700us/step - loss: 0.2675\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2672\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2658\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2664\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 620us/step - loss: 0.2659\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2664\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 592us/step - loss: 0.2665\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2653\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2667\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2661\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 656us/step - loss: 0.2651\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2653\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 670us/step - loss: 0.2640\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2648\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 690us/step - loss: 0.2643\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 679us/step - loss: 0.2652\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 0.2647\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2637\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 689us/step - loss: 0.2645\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2639\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2633\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 588us/step - loss: 0.2630\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2629\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 690us/step - loss: 0.2628\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 616us/step - loss: 0.2628\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2626\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 712us/step - loss: 0.2627\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2622\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 0.2622\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 676us/step - loss: 0.2621\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2621\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.2797\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 30.4174\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 650us/step - loss: 30.0025\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 622us/step - loss: 29.3861\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 28.5442\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 27.4681\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 26.1721\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 705us/step - loss: 24.6683\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 674us/step - loss: 23.0084\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 677us/step - loss: 21.1975\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 685us/step - loss: 19.3331\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 655us/step - loss: 17.3868\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 15.4371\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 682us/step - loss: 13.5254\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 11.6699\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 661us/step - loss: 9.9354\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 8.3215\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 6.8640\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 5.5833\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 4.4724\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 630us/step - loss: 3.5161\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 2.7302\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 2.0923\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 658us/step - loss: 1.5892\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 1.2077\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.9060\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.7005\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.5529\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.4452\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 688us/step - loss: 0.3783\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3321\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.3039\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2836\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2722\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2658\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2610\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2584\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2565\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2558\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 704us/step - loss: 0.2553\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2550\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 567us/step - loss: 0.2549\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2549\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 726us/step - loss: 0.2545\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2544\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 670us/step - loss: 0.2544\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2542\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2544\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2543\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2541\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2545\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2542\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2541\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 637us/step - loss: 0.2538\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2554\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2544\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2539\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2535\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2535\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 693us/step - loss: 0.2536\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2535\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2534\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 651us/step - loss: 0.2535\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 632us/step - loss: 0.2536\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2531\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2536\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 671us/step - loss: 0.2535\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2534\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2529\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2532\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2529\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2527\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2527\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2531\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 622us/step - loss: 0.2529\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2525\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2524\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 656us/step - loss: 0.2523\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 684us/step - loss: 0.2531\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 0.2529\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2523\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2520\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2522\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 613us/step - loss: 0.2522\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 606us/step - loss: 0.2519\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 638us/step - loss: 0.2516\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2521\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2519\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 619us/step - loss: 0.2522\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2526\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 628us/step - loss: 0.2518\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2528\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2513\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 674us/step - loss: 0.2511\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 682us/step - loss: 0.2514\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2512\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 648us/step - loss: 0.2515\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 712us/step - loss: 0.2524\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 633us/step - loss: 0.2520\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2509\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4085\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 717us/step - loss: 30.9349\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 30.5673\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 30.1423\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 29.5950\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 28.9382\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 28.1425\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 27.2640\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 26.2361\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 25.1430\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 23.9622\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 22.7108\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 21.3965\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 20.0604\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 18.6657\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 17.2917\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 15.9025\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 14.5238\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 13.1967\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 659us/step - loss: 11.8811\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 10.6527\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 657us/step - loss: 9.4807\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 8.3585\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 7.3246\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 6.3748\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 5.4802\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 4.7025\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 3.9982\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 626us/step - loss: 3.3692\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 2.8241\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 2.3562\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 1.9543\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 1.6139\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 697us/step - loss: 1.3265\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 669us/step - loss: 1.0959\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.9069\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 676us/step - loss: 0.7590\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 705us/step - loss: 0.6412\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 600us/step - loss: 0.5513\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 629us/step - loss: 0.4762\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.4244\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.3817\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 620us/step - loss: 0.3499\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3273\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.3106\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 621us/step - loss: 0.3003\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 605us/step - loss: 0.2910\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2857\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2816\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2793\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2772\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2760\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2751\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2744\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 628us/step - loss: 0.2741\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2739\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 683us/step - loss: 0.2735\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 618us/step - loss: 0.2731\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2731\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 627us/step - loss: 0.2729\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 647us/step - loss: 0.2730\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2728\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 657us/step - loss: 0.2729\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 655us/step - loss: 0.2729\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 613us/step - loss: 0.2728\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 693us/step - loss: 0.2729\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 659us/step - loss: 0.2738\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2726\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 667us/step - loss: 0.2726\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.2723\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2724\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 671us/step - loss: 0.2723\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2722\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 692us/step - loss: 0.2722\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 677us/step - loss: 0.2722\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 691us/step - loss: 0.2720\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 701us/step - loss: 0.2720\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 661us/step - loss: 0.2722\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 688us/step - loss: 0.2722\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 670us/step - loss: 0.2726\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 659us/step - loss: 0.2719\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 684us/step - loss: 0.2717\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 649us/step - loss: 0.2719\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 692us/step - loss: 0.2719\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 699us/step - loss: 0.2715\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 715us/step - loss: 0.2717\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2714\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2714\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 589us/step - loss: 0.2713\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 593us/step - loss: 0.2714\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 638us/step - loss: 0.2711\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 591us/step - loss: 0.2711\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 590us/step - loss: 0.2715\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2712\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2710\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2709\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2710\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2709\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2710\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2708\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 0.2706\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2102\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 30.0158\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 29.3975\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 28.5096\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 634us/step - loss: 27.3458\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 652us/step - loss: 25.8907\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 692us/step - loss: 24.1205\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 694us/step - loss: 22.1660\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 689us/step - loss: 19.9826\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 17.7536\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 15.4057\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 13.1748\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 10.9869\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 676us/step - loss: 8.9424\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 7.1513\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 5.5549\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 4.2097\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 3.1073\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 667us/step - loss: 2.2678\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 623us/step - loss: 1.6227\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 1.1535\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.8325\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 689us/step - loss: 0.6162\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 667us/step - loss: 0.4807\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 658us/step - loss: 0.3961\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 656us/step - loss: 0.3480\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.3188\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.3015\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 0.2930\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2888\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2869\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 0.2858\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 685us/step - loss: 0.2849\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 628us/step - loss: 0.2849\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2844\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 642us/step - loss: 0.2843\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 689us/step - loss: 0.2845\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2844\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2842\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2844\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2842\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2842\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2840\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2846\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2840\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2840\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2844\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2855\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2832\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2842\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 720us/step - loss: 0.2836\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2831\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 682us/step - loss: 0.2833\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2830\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 627us/step - loss: 0.2837\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 652us/step - loss: 0.2827\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 675us/step - loss: 0.2834\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2827\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2828\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2830\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 667us/step - loss: 0.2822\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2827\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 666us/step - loss: 0.2824\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 724us/step - loss: 0.2828\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 625us/step - loss: 0.2822\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2827\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2823\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2822\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 636us/step - loss: 0.2830\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2820\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2818\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2818\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2813\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2815\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 678us/step - loss: 0.2817\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2821\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2811\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 727us/step - loss: 0.2810\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 680us/step - loss: 0.2809\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 708us/step - loss: 0.2809\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2812\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 666us/step - loss: 0.2815\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 0.2812\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 669us/step - loss: 0.2808\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 700us/step - loss: 0.2802\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2805\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 698us/step - loss: 0.2812\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 681us/step - loss: 0.2803\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2797\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 705us/step - loss: 0.2802\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 629us/step - loss: 0.2799\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2805\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 660us/step - loss: 0.2794\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 693us/step - loss: 0.2801\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 635us/step - loss: 0.2799\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 662us/step - loss: 0.2805\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2788\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2798\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 674us/step - loss: 0.2793\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.2790\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 680us/step - loss: 0.2790\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1158\n",
      "Baseline Mean (-0.27) MSE (0.11) \n",
      "Baseline RMSE: 0.3290127968819601\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 30.1489 - val_loss: 29.7243\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 29.4639 - val_loss: 28.8669\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 28.4596 - val_loss: 27.6572\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 27.0920 - val_loss: 26.0699\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 25.3812 - val_loss: 24.1225\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 23.3440 - val_loss: 21.9202\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 21.0429 - val_loss: 19.5372\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 18.6290 - val_loss: 16.9805\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 16.0956 - val_loss: 14.4362\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 13.5797 - val_loss: 11.9849\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 11.2198 - val_loss: 9.6134\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 8.9666 - val_loss: 7.5502\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 7.0056 - val_loss: 5.7236\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 5.2923 - val_loss: 4.2195\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.9022 - val_loss: 2.9929\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.7811 - val_loss: 2.0866\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.9533 - val_loss: 1.4199\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.3495 - val_loss: 0.9642\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9333 - val_loss: 0.6766\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6610 - val_loss: 0.5069\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4964 - val_loss: 0.4079\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3613\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3430\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3362\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 0.3373\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2779 - val_loss: 0.3400\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.3454\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.3472\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.3483\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2706 - val_loss: 0.3511\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.3500\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.3524\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2696 - val_loss: 0.3548\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2697 - val_loss: 0.3563\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2702 - val_loss: 0.3548\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2695 - val_loss: 0.3557\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.3541\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2691 - val_loss: 0.3553\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2697 - val_loss: 0.3552\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2690 - val_loss: 0.3568\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2692 - val_loss: 0.3562\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2690 - val_loss: 0.3552\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3581\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2691 - val_loss: 0.3544\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.3544\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2689 - val_loss: 0.3544\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.3565\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.3571\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3547\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.3577\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3536\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2689 - val_loss: 0.3569\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3558\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3555\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.3521\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3553\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2680 - val_loss: 0.3579\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.3552\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3541\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3585\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2670 - val_loss: 0.3569\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.3559\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3553\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2675 - val_loss: 0.3566\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2666 - val_loss: 0.3536\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2662 - val_loss: 0.3574\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3561\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2666 - val_loss: 0.3573\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2666 - val_loss: 0.3539\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3578\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3561\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2660 - val_loss: 0.3546\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2657 - val_loss: 0.3572\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2663 - val_loss: 0.3538\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3565\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2663 - val_loss: 0.3577\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2665 - val_loss: 0.3535\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2650 - val_loss: 0.3582\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2651 - val_loss: 0.3601\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.3581\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3543\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2644 - val_loss: 0.3583\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2651 - val_loss: 0.3600\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.3530\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2641 - val_loss: 0.3554\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.3620\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.3540\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.3582\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.3575\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2645 - val_loss: 0.3582\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2644 - val_loss: 0.3565\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.3592\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2646 - val_loss: 0.3581\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.3550\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.3591\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2633 - val_loss: 0.3567\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2629 - val_loss: 0.3597\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3564\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3600\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2642 - val_loss: 0.3542\n",
      "Neural network MSE: 0.35415423\n",
      "Neural network RMSE: 0.59510857\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6] \n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "ROW_DIM = 0\n",
    "COL_DIM = 1\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "# Split the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped, \n",
    "         y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Define the model.\n",
    "def create_model():\n",
    "   model = Sequential()\n",
    "   model.add(Dense(5, input_dim=5, kernel_initializer='normal', \n",
    "             activation='relu'))\n",
    "   model.add(Dense(1, kernel_initializer='normal'))\n",
    "   model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "   return model\n",
    "\n",
    "# Since this is a linear regression use KerasRegressor.\n",
    "estimator = KerasRegressor(build_fn=create_model, epochs=100,\n",
    "                           batch_size=5, verbose=1)\n",
    "\n",
    "# Use kfold analysis for a more reliable estimate.\n",
    "kfold   = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "print(\"Baseline Mean (%.2f) MSE (%.2f) \" % (results.mean(), results.std()))\n",
    "print(\"Baseline RMSE: \" + str(np.sqrt(results.std())))\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "# Build the model.\n",
    "model   = create_model()\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    batch_size=5, verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model.\n",
    "predictions = model.predict(X_test)\n",
    "mse         = metrics.mean_squared_error(y_test, predictions)\n",
    "print(\"Neural network MSE: \" + str(mse))\n",
    "print(\"Neural network RMSE: \" + str(np.sqrt(mse)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> As you can see, for our Neural Network baseline, our RMSE value is already lower than the OLS model without any adjustments. Lets adjust some parameters of the model and try to get the RMSE value down even further. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We will first try grid searching for better batch size and epoch values.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   23.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   34.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 748us/step - loss: 30.4671\n",
      "Epoch 2/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 30.4000\n",
      "Epoch 3/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.3334\n",
      "Epoch 4/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.2645\n",
      "Epoch 5/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.1921\n",
      "Epoch 6/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.1156\n",
      "Epoch 7/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.0352\n",
      "Epoch 8/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.9515\n",
      "Epoch 9/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.8612\n",
      "Epoch 10/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.7674\n",
      "Epoch 11/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 29.6675\n",
      "Epoch 12/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.5625\n",
      "Epoch 13/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.4534\n",
      "Epoch 14/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.3380\n",
      "Epoch 15/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.2185\n",
      "Epoch 16/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.0921\n",
      "Epoch 17/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.9602\n",
      "Epoch 18/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.8236\n",
      "Epoch 19/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 28.6797\n",
      "Epoch 20/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 28.5326\n",
      "Epoch 21/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.3767\n",
      "Epoch 22/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.2139\n",
      "Epoch 23/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.0495\n",
      "Epoch 24/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 27.8714\n",
      "Epoch 25/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.6938\n",
      "Epoch 26/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.5078\n",
      "Epoch 27/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 27.3238\n",
      "Epoch 28/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 27.1279\n",
      "Epoch 29/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 26.9281\n",
      "Epoch 30/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 26.7238\n",
      "Epoch 31/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 26.5153\n",
      "Epoch 32/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 26.2982\n",
      "Epoch 33/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 26.0793\n",
      "Epoch 34/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 25.8542\n",
      "Epoch 35/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 25.6288\n",
      "Epoch 36/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 25.3913\n",
      "Epoch 37/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 25.1494\n",
      "Epoch 38/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 24.9088\n",
      "Epoch 39/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 24.6664\n",
      "Epoch 40/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 24.4190\n",
      "Epoch 41/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 24.1668\n",
      "Epoch 42/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 23.9043\n",
      "Epoch 43/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.6472\n",
      "Epoch 44/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.3808\n",
      "Epoch 45/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.1210\n",
      "Epoch 46/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22.8516\n",
      "Epoch 47/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22.5833\n",
      "Epoch 48/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 22.3194\n",
      "Epoch 49/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 22.0437\n",
      "Epoch 50/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 21.7662\n",
      "Epoch 51/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 21.4873\n",
      "Epoch 52/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 21.2030\n",
      "Epoch 53/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 20.9261\n",
      "Epoch 54/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 20.6382\n",
      "Epoch 55/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 20.3481\n",
      "Epoch 56/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 20.0565\n",
      "Epoch 57/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 19.7657\n",
      "Epoch 58/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19.4719\n",
      "Epoch 59/400\n",
      "5/5 [==============================] - 0s 893us/step - loss: 19.1690\n",
      "Epoch 60/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 18.8758\n",
      "Epoch 61/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 18.5748\n",
      "Epoch 62/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 18.2755\n",
      "Epoch 63/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 17.9805\n",
      "Epoch 64/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17.6854\n",
      "Epoch 65/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 17.3871\n",
      "Epoch 66/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 17.0939\n",
      "Epoch 67/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 16.7903\n",
      "Epoch 68/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 16.4906\n",
      "Epoch 69/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 16.1895\n",
      "Epoch 70/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 15.8836\n",
      "Epoch 71/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 15.5799\n",
      "Epoch 72/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 15.2785\n",
      "Epoch 73/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 14.9782\n",
      "Epoch 74/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 14.6728\n",
      "Epoch 75/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 14.3778\n",
      "Epoch 76/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 14.0787\n",
      "Epoch 77/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 13.7844\n",
      "Epoch 78/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 13.4896\n",
      "Epoch 79/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 13.1932\n",
      "Epoch 80/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 12.9034\n",
      "Epoch 81/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12.6159\n",
      "Epoch 82/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 12.3369\n",
      "Epoch 83/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12.0498\n",
      "Epoch 84/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 11.7713\n",
      "Epoch 85/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 11.5002\n",
      "Epoch 86/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 11.2356\n",
      "Epoch 87/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 10.9737\n",
      "Epoch 88/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 10.7134\n",
      "Epoch 89/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 10.4479\n",
      "Epoch 90/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 10.1886\n",
      "Epoch 91/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 9.9195\n",
      "Epoch 92/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.6664\n",
      "Epoch 93/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4098\n",
      "Epoch 94/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.1621\n",
      "Epoch 95/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.9148\n",
      "Epoch 96/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6694\n",
      "Epoch 97/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4321\n",
      "Epoch 98/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8.1938\n",
      "Epoch 99/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7.9550\n",
      "Epoch 100/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7247\n",
      "Epoch 101/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.5005\n",
      "Epoch 102/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2758\n",
      "Epoch 103/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.0595\n",
      "Epoch 104/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8495\n",
      "Epoch 105/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.6409\n",
      "Epoch 106/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.4392\n",
      "Epoch 107/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6.2395\n",
      "Epoch 108/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0445\n",
      "Epoch 109/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8519\n",
      "Epoch 110/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6661\n",
      "Epoch 111/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5.4850\n",
      "Epoch 112/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3079\n",
      "Epoch 113/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.1290\n",
      "Epoch 114/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4.9579\n",
      "Epoch 115/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4.7863\n",
      "Epoch 116/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6225\n",
      "Epoch 117/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4.4625\n",
      "Epoch 118/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4.3054\n",
      "Epoch 119/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4.1574\n",
      "Epoch 120/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 4.0085\n",
      "Epoch 121/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3.8627\n",
      "Epoch 122/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3.7216\n",
      "Epoch 123/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3.5846\n",
      "Epoch 124/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 3.4480\n",
      "Epoch 125/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 3.3171\n",
      "Epoch 126/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 3.1877\n",
      "Epoch 127/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 3.0678\n",
      "Epoch 128/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 2.9513\n",
      "Epoch 129/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 2.8385\n",
      "Epoch 130/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2.7314\n",
      "Epoch 131/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2.6265\n",
      "Epoch 132/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 2.5261\n",
      "Epoch 133/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 2.4290\n",
      "Epoch 134/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2.3350\n",
      "Epoch 135/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 2.2420\n",
      "Epoch 136/400\n",
      "5/5 [==============================] - 0s 741us/step - loss: 2.1536\n",
      "Epoch 137/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 2.0674\n",
      "Epoch 138/400\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.9822\n",
      "Epoch 139/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.9039\n",
      "Epoch 140/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 1.8259\n",
      "Epoch 141/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.7488\n",
      "Epoch 142/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 1.6764\n",
      "Epoch 143/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.6079\n",
      "Epoch 144/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 1.5422\n",
      "Epoch 145/400\n",
      "5/5 [==============================] - 0s 991us/step - loss: 1.4793\n",
      "Epoch 146/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.4188\n",
      "Epoch 147/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.3593\n",
      "Epoch 148/400\n",
      "5/5 [==============================] - 0s 742us/step - loss: 1.3026\n",
      "Epoch 149/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.2486\n",
      "Epoch 150/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.1962\n",
      "Epoch 151/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.1459\n",
      "Epoch 152/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0985\n",
      "Epoch 153/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 1.0522\n",
      "Epoch 154/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0107\n",
      "Epoch 155/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9709\n",
      "Epoch 156/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.9327\n",
      "Epoch 157/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.8963\n",
      "Epoch 158/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8594\n",
      "Epoch 159/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.8263\n",
      "Epoch 160/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7935\n",
      "Epoch 161/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7620\n",
      "Epoch 162/400\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.7343\n",
      "Epoch 163/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7082\n",
      "Epoch 164/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6827\n",
      "Epoch 165/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6580\n",
      "Epoch 166/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6336\n",
      "Epoch 167/400\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.6114\n",
      "Epoch 168/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5891\n",
      "Epoch 169/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5690\n",
      "Epoch 170/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5500\n",
      "Epoch 171/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.5331\n",
      "Epoch 172/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5169\n",
      "Epoch 173/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5016\n",
      "Epoch 174/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.4862\n",
      "Epoch 175/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4715\n",
      "Epoch 176/400\n",
      "5/5 [==============================] - 0s 990us/step - loss: 0.4574\n",
      "Epoch 177/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4439\n",
      "Epoch 178/400\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.4322\n",
      "Epoch 179/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4217\n",
      "Epoch 180/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.4121\n",
      "Epoch 181/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.4024\n",
      "Epoch 182/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3943\n",
      "Epoch 183/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3856\n",
      "Epoch 184/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3778\n",
      "Epoch 185/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3700\n",
      "Epoch 186/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3628\n",
      "Epoch 187/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3556\n",
      "Epoch 188/400\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.3489\n",
      "Epoch 189/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3424\n",
      "Epoch 190/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3358\n",
      "Epoch 191/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3301\n",
      "Epoch 192/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3254\n",
      "Epoch 193/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3207\n",
      "Epoch 194/400\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.3164\n",
      "Epoch 195/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.3124\n",
      "Epoch 196/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3085\n",
      "Epoch 197/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3058\n",
      "Epoch 198/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3023\n",
      "Epoch 199/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2992\n",
      "Epoch 200/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2969\n",
      "Epoch 201/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2948\n",
      "Epoch 202/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 991us/step - loss: 0.2922\n",
      "Epoch 203/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2904\n",
      "Epoch 204/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2883\n",
      "Epoch 205/400\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.2864\n",
      "Epoch 206/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2848\n",
      "Epoch 207/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2834\n",
      "Epoch 208/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2822\n",
      "Epoch 209/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2809\n",
      "Epoch 210/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2796\n",
      "Epoch 211/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2784\n",
      "Epoch 212/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2773\n",
      "Epoch 213/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2763\n",
      "Epoch 214/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2756\n",
      "Epoch 215/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2748\n",
      "Epoch 216/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2741\n",
      "Epoch 217/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2736\n",
      "Epoch 218/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2731\n",
      "Epoch 219/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2726\n",
      "Epoch 220/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2721\n",
      "Epoch 221/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.2717\n",
      "Epoch 222/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2715\n",
      "Epoch 223/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2710\n",
      "Epoch 224/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.2705\n",
      "Epoch 225/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2703\n",
      "Epoch 226/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2698\n",
      "Epoch 227/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2696\n",
      "Epoch 228/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.2694\n",
      "Epoch 229/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2692\n",
      "Epoch 230/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2689\n",
      "Epoch 231/400\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.2688\n",
      "Epoch 232/400\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.2686\n",
      "Epoch 233/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.2685\n",
      "Epoch 234/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.2682\n",
      "Epoch 235/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2681\n",
      "Epoch 236/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2680\n",
      "Epoch 237/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2681\n",
      "Epoch 238/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2679\n",
      "Epoch 239/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.2679\n",
      "Epoch 240/400\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.2678\n",
      "Epoch 241/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2678\n",
      "Epoch 242/400\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.2678\n",
      "Epoch 243/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2677\n",
      "Epoch 244/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2677\n",
      "Epoch 245/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2677\n",
      "Epoch 246/400\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2676\n",
      "Epoch 247/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2676\n",
      "Epoch 248/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2675\n",
      "Epoch 249/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2675\n",
      "Epoch 250/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2675\n",
      "Epoch 251/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2674\n",
      "Epoch 252/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2674\n",
      "Epoch 253/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2674\n",
      "Epoch 254/400\n",
      "5/5 [==============================] - 0s 875us/step - loss: 0.2674\n",
      "Epoch 255/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2674\n",
      "Epoch 256/400\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.2674\n",
      "Epoch 257/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 258/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2674\n",
      "Epoch 259/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2674\n",
      "Epoch 260/400\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.2673\n",
      "Epoch 261/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2674\n",
      "Epoch 262/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 263/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 264/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 265/400\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.2673\n",
      "Epoch 266/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2674\n",
      "Epoch 267/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2674\n",
      "Epoch 268/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2673\n",
      "Epoch 269/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 270/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2673\n",
      "Epoch 271/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 272/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 273/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 274/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 275/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2672\n",
      "Epoch 276/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 277/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 278/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 279/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 280/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 281/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 282/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 283/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 284/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2673\n",
      "Epoch 285/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 286/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2672\n",
      "Epoch 287/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 288/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 289/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 290/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2672\n",
      "Epoch 291/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2672\n",
      "Epoch 292/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2671\n",
      "Epoch 293/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 294/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 295/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 296/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2671\n",
      "Epoch 297/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2671\n",
      "Epoch 298/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2670\n",
      "Epoch 299/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2670\n",
      "Epoch 300/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2670\n",
      "Epoch 301/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2670\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2670\n",
      "Epoch 303/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2669\n",
      "Epoch 304/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2670\n",
      "Epoch 305/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2669\n",
      "Epoch 306/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2669\n",
      "Epoch 307/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2669\n",
      "Epoch 308/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2669\n",
      "Epoch 309/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2669\n",
      "Epoch 310/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2669\n",
      "Epoch 311/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2669\n",
      "Epoch 312/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 313/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2670\n",
      "Epoch 314/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2668\n",
      "Epoch 315/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2668\n",
      "Epoch 316/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 317/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2668\n",
      "Epoch 318/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 319/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 320/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2668\n",
      "Epoch 321/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 322/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 323/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 324/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 325/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 326/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 327/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 328/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 329/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 330/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 331/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 332/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 333/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2668\n",
      "Epoch 334/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 335/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 336/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 337/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 338/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 339/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 340/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 341/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 342/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 343/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 344/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 345/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 346/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 347/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2666\n",
      "Epoch 348/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2666\n",
      "Epoch 349/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 350/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2667\n",
      "Epoch 351/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2666\n",
      "Epoch 352/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 353/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2666\n",
      "Epoch 354/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 355/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 356/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 357/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 358/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2666\n",
      "Epoch 359/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 360/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 361/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 362/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2667\n",
      "Epoch 363/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2668\n",
      "Epoch 364/400\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2668\n",
      "Epoch 365/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 366/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 367/400\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2668\n",
      "Epoch 368/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2668\n",
      "Epoch 369/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2668\n",
      "Epoch 370/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2666\n",
      "Epoch 371/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2665\n",
      "Epoch 372/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2665\n",
      "Epoch 373/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2664\n",
      "Epoch 374/400\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.2663\n",
      "Epoch 375/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2663\n",
      "Epoch 376/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2663\n",
      "Epoch 377/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2663\n",
      "Epoch 378/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2663\n",
      "Epoch 379/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2663\n",
      "Epoch 380/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.2662\n",
      "Epoch 381/400\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.2662\n",
      "Epoch 382/400\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.2662\n",
      "Epoch 383/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2662\n",
      "Epoch 384/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2660\n",
      "Epoch 385/400\n",
      "5/5 [==============================] - 0s 727us/step - loss: 0.2662\n",
      "Epoch 386/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2661\n",
      "Epoch 387/400\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2660\n",
      "Epoch 388/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2661\n",
      "Epoch 389/400\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.2660\n",
      "Epoch 390/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2660\n",
      "Epoch 391/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2661\n",
      "Epoch 392/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2660\n",
      "Epoch 393/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2661\n",
      "Epoch 394/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2660\n",
      "Epoch 395/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2660\n",
      "Epoch 396/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2659\n",
      "Epoch 397/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2661\n",
      "Epoch 398/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2660\n",
      "Epoch 399/400\n",
      "5/5 [==============================] - 0s 682us/step - loss: 0.2659\n",
      "Epoch 400/400\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2659\n",
      "Best: -0.270225 using {'batch_size': 30, 'epochs': 400}\n",
      "-0.407030 (0.060494) with: {'batch_size': 10, 'epochs': 100}\n",
      "-0.272995 (0.044834) with: {'batch_size': 10, 'epochs': 200}\n",
      "-0.281479 (0.047136) with: {'batch_size': 10, 'epochs': 300}\n",
      "-0.285784 (0.047702) with: {'batch_size': 10, 'epochs': 400}\n",
      "-0.291716 (0.050176) with: {'batch_size': 10, 'epochs': 500}\n",
      "-3.948734 (3.155532) with: {'batch_size': 20, 'epochs': 100}\n",
      "-0.274597 (0.051436) with: {'batch_size': 20, 'epochs': 200}\n",
      "-0.281434 (0.051716) with: {'batch_size': 20, 'epochs': 300}\n",
      "-0.280021 (0.046823) with: {'batch_size': 20, 'epochs': 400}\n",
      "-0.278438 (0.035876) with: {'batch_size': 20, 'epochs': 500}\n",
      "-12.884811 (5.493862) with: {'batch_size': 30, 'epochs': 100}\n",
      "-8.636276 (11.065627) with: {'batch_size': 30, 'epochs': 200}\n",
      "-0.307219 (0.091923) with: {'batch_size': 30, 'epochs': 300}\n",
      "-0.270225 (0.041217) with: {'batch_size': 30, 'epochs': 400}\n",
      "-0.276129 (0.050224) with: {'batch_size': 30, 'epochs': 500}\n",
      "-16.682519 (3.457585) with: {'batch_size': 40, 'epochs': 100}\n",
      "-0.360653 (0.068938) with: {'batch_size': 40, 'epochs': 200}\n",
      "-0.270850 (0.048225) with: {'batch_size': 40, 'epochs': 300}\n",
      "-0.278489 (0.041766) with: {'batch_size': 40, 'epochs': 400}\n",
      "-5.275209 (7.115575) with: {'batch_size': 40, 'epochs': 500}\n",
      "-20.651383 (3.466159) with: {'batch_size': 50, 'epochs': 100}\n",
      "-4.088042 (1.235588) with: {'batch_size': 50, 'epochs': 200}\n",
      "-0.476637 (0.109029) with: {'batch_size': 50, 'epochs': 300}\n",
      "-0.272040 (0.050311) with: {'batch_size': 50, 'epochs': 400}\n",
      "-0.299732 (0.040107) with: {'batch_size': 50, 'epochs': 500}\n"
     ]
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6] \n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "ROW_DIM = 0\n",
    "COL_DIM = 1\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped,\n",
    "                      y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers                import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model.\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer='normal',\n",
    "                        activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size  = [10, 20, 30, 40, 50]\n",
    "epochs      = [100,200,300,400,500]\n",
    "param_grid  = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid        = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           n_jobs=-1, cv=3, verbose=1)\n",
    "#################################################\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means   = grid_result.cv_results_['mean_test_score']\n",
    "stds    = grid_result.cv_results_['std_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The best option for batch_size is 20 and epochs is 400. Next, we will grid search for a good optimizer to use in the network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4602\n",
      "Epoch 2/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.3885\n",
      "Epoch 3/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 30.3153\n",
      "Epoch 4/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.2396\n",
      "Epoch 5/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.1565\n",
      "Epoch 6/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.0698\n",
      "Epoch 7/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 29.9767\n",
      "Epoch 8/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.8772\n",
      "Epoch 9/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.7691\n",
      "Epoch 10/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.6528\n",
      "Epoch 11/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.5333\n",
      "Epoch 12/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 29.4045\n",
      "Epoch 13/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.2675\n",
      "Epoch 14/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 29.1293\n",
      "Epoch 15/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 28.9847\n",
      "Epoch 16/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 28.8311\n",
      "Epoch 17/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 28.6760\n",
      "Epoch 18/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 28.5115\n",
      "Epoch 19/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.3371\n",
      "Epoch 20/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 28.1531\n",
      "Epoch 21/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 27.9680\n",
      "Epoch 22/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 27.7842\n",
      "Epoch 23/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 27.5951\n",
      "Epoch 24/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 27.3949\n",
      "Epoch 25/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 27.1895\n",
      "Epoch 26/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 26.9802\n",
      "Epoch 27/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 26.7679\n",
      "Epoch 28/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 26.5526\n",
      "Epoch 29/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 26.3360\n",
      "Epoch 30/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 26.1055\n",
      "Epoch 31/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 25.8717\n",
      "Epoch 32/400\n",
      "7/7 [==============================] - 0s 923us/step - loss: 25.6310\n",
      "Epoch 33/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 25.3778\n",
      "Epoch 34/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 25.1140\n",
      "Epoch 35/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 24.8467\n",
      "Epoch 36/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 24.5780\n",
      "Epoch 37/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 24.2997\n",
      "Epoch 38/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 24.0383\n",
      "Epoch 39/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 23.7788\n",
      "Epoch 40/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 23.5131\n",
      "Epoch 41/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 23.2390\n",
      "Epoch 42/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 22.9575\n",
      "Epoch 43/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 22.6613\n",
      "Epoch 44/400\n",
      "7/7 [==============================] - 0s 931us/step - loss: 22.3582\n",
      "Epoch 45/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 22.0510\n",
      "Epoch 46/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 21.7393\n",
      "Epoch 47/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 21.4128\n",
      "Epoch 48/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 21.0933\n",
      "Epoch 49/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 20.8059\n",
      "Epoch 50/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 20.5532\n",
      "Epoch 51/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 20.2969\n",
      "Epoch 52/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 20.0350\n",
      "Epoch 53/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 19.7660\n",
      "Epoch 54/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 19.4902\n",
      "Epoch 55/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 19.2093\n",
      "Epoch 56/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 18.9243\n",
      "Epoch 57/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 18.6303\n",
      "Epoch 58/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 18.3301\n",
      "Epoch 59/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 18.0300\n",
      "Epoch 60/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 17.7151\n",
      "Epoch 61/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 17.4055\n",
      "Epoch 62/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 17.0917\n",
      "Epoch 63/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 16.7821\n",
      "Epoch 64/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 16.4713\n",
      "Epoch 65/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 16.1539\n",
      "Epoch 66/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 15.8352\n",
      "Epoch 67/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 15.5091\n",
      "Epoch 68/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 15.1853\n",
      "Epoch 69/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 14.8704\n",
      "Epoch 70/400\n",
      "7/7 [==============================] - 0s 754us/step - loss: 14.5457\n",
      "Epoch 71/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 14.2166\n",
      "Epoch 72/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 13.8891\n",
      "Epoch 73/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 13.5535\n",
      "Epoch 74/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 13.2209\n",
      "Epoch 75/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 12.8757\n",
      "Epoch 76/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 12.5364\n",
      "Epoch 77/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 12.2001\n",
      "Epoch 78/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 11.8531\n",
      "Epoch 79/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 11.5189\n",
      "Epoch 80/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 11.1796\n",
      "Epoch 81/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 10.8529\n",
      "Epoch 82/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 10.5254\n",
      "Epoch 83/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 10.1972\n",
      "Epoch 84/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 9.8679\n",
      "Epoch 85/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 9.5384\n",
      "Epoch 86/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 9.2218\n",
      "Epoch 87/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 8.8892\n",
      "Epoch 88/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 8.5718\n",
      "Epoch 89/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 8.2547\n",
      "Epoch 90/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 7.9401\n",
      "Epoch 91/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 7.6465\n",
      "Epoch 92/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 7.3680\n",
      "Epoch 93/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 7.0960\n",
      "Epoch 94/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 6.8263\n",
      "Epoch 95/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 6.5621\n",
      "Epoch 96/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 6.3083\n",
      "Epoch 97/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 6.0557\n",
      "Epoch 98/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 5.8145\n",
      "Epoch 99/400\n",
      "7/7 [==============================] - 0s 820us/step - loss: 5.5672\n",
      "Epoch 100/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 5.3252\n",
      "Epoch 101/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 665us/step - loss: 5.0905\n",
      "Epoch 102/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.8610\n",
      "Epoch 103/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.6392\n",
      "Epoch 104/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.4204\n",
      "Epoch 105/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 4.2029\n",
      "Epoch 106/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.9956\n",
      "Epoch 107/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.7941\n",
      "Epoch 108/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.5999\n",
      "Epoch 109/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 3.4126\n",
      "Epoch 110/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 3.2331\n",
      "Epoch 111/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 3.0603\n",
      "Epoch 112/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.8936\n",
      "Epoch 113/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.7371\n",
      "Epoch 114/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.5809\n",
      "Epoch 115/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.4377\n",
      "Epoch 116/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.2992\n",
      "Epoch 117/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.1649\n",
      "Epoch 118/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 2.0389\n",
      "Epoch 119/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.9223\n",
      "Epoch 120/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.8065\n",
      "Epoch 121/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.6963\n",
      "Epoch 122/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.5906\n",
      "Epoch 123/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.4916\n",
      "Epoch 124/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.3998\n",
      "Epoch 125/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.3113\n",
      "Epoch 126/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.2274\n",
      "Epoch 127/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.1525\n",
      "Epoch 128/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.0797\n",
      "Epoch 129/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.0129\n",
      "Epoch 130/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.9491\n",
      "Epoch 131/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.8905\n",
      "Epoch 132/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.8366\n",
      "Epoch 133/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.7860\n",
      "Epoch 134/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.7403\n",
      "Epoch 135/400\n",
      "7/7 [==============================] - 0s 838us/step - loss: 0.6958\n",
      "Epoch 136/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.6565\n",
      "Epoch 137/400\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.6198\n",
      "Epoch 138/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.5872\n",
      "Epoch 139/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.5567\n",
      "Epoch 140/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.5275\n",
      "Epoch 141/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.5013\n",
      "Epoch 142/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4770\n",
      "Epoch 143/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4549\n",
      "Epoch 144/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4354\n",
      "Epoch 145/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4179\n",
      "Epoch 146/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.4005\n",
      "Epoch 147/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3862\n",
      "Epoch 148/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3738\n",
      "Epoch 149/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3613\n",
      "Epoch 150/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3507\n",
      "Epoch 151/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3409\n",
      "Epoch 152/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3315\n",
      "Epoch 153/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.3241\n",
      "Epoch 154/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3168\n",
      "Epoch 155/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3109\n",
      "Epoch 156/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3046\n",
      "Epoch 157/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3001\n",
      "Epoch 158/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2952\n",
      "Epoch 159/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2907\n",
      "Epoch 160/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2868\n",
      "Epoch 161/400\n",
      "7/7 [==============================] - 0s 663us/step - loss: 0.2838\n",
      "Epoch 162/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2810\n",
      "Epoch 163/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2781\n",
      "Epoch 164/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2760\n",
      "Epoch 165/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2743\n",
      "Epoch 166/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2723\n",
      "Epoch 167/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2708\n",
      "Epoch 168/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2693\n",
      "Epoch 169/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2681\n",
      "Epoch 170/400\n",
      "7/7 [==============================] - 0s 834us/step - loss: 0.2668\n",
      "Epoch 171/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2659\n",
      "Epoch 172/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2652\n",
      "Epoch 173/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2644\n",
      "Epoch 174/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2640\n",
      "Epoch 175/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2633\n",
      "Epoch 176/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2629\n",
      "Epoch 177/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2626\n",
      "Epoch 178/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2624\n",
      "Epoch 179/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2624\n",
      "Epoch 180/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2621\n",
      "Epoch 181/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2621\n",
      "Epoch 182/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2621\n",
      "Epoch 183/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2618\n",
      "Epoch 184/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2617\n",
      "Epoch 185/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2617\n",
      "Epoch 186/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2615\n",
      "Epoch 187/400\n",
      "7/7 [==============================] - 0s 660us/step - loss: 0.2614\n",
      "Epoch 188/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2613\n",
      "Epoch 189/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2613\n",
      "Epoch 190/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 191/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 192/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 193/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2612\n",
      "Epoch 194/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 195/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.2612\n",
      "Epoch 196/400\n",
      "7/7 [==============================] - 0s 666us/step - loss: 0.2612\n",
      "Epoch 197/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 198/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2613\n",
      "Epoch 199/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2612\n",
      "Epoch 200/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2611\n",
      "Epoch 201/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 836us/step - loss: 0.2613\n",
      "Epoch 202/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2613\n",
      "Epoch 203/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2614\n",
      "Epoch 204/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2614\n",
      "Epoch 205/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2613\n",
      "Epoch 206/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2612\n",
      "Epoch 207/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2612\n",
      "Epoch 208/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 209/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2613\n",
      "Epoch 210/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2611\n",
      "Epoch 211/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2611\n",
      "Epoch 212/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2611\n",
      "Epoch 213/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2611\n",
      "Epoch 214/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2611\n",
      "Epoch 215/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2611\n",
      "Epoch 216/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2609\n",
      "Epoch 217/400\n",
      "7/7 [==============================] - 0s 837us/step - loss: 0.2610\n",
      "Epoch 218/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2609\n",
      "Epoch 219/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2610\n",
      "Epoch 220/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2609\n",
      "Epoch 221/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2610\n",
      "Epoch 222/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2610\n",
      "Epoch 223/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2609\n",
      "Epoch 224/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2610\n",
      "Epoch 225/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2610\n",
      "Epoch 226/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2609\n",
      "Epoch 227/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2609\n",
      "Epoch 228/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2609\n",
      "Epoch 229/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2612\n",
      "Epoch 230/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2610\n",
      "Epoch 231/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2610\n",
      "Epoch 232/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2609\n",
      "Epoch 233/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2609\n",
      "Epoch 234/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2609\n",
      "Epoch 235/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2609\n",
      "Epoch 236/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2609\n",
      "Epoch 237/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2608\n",
      "Epoch 238/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2609\n",
      "Epoch 239/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2609\n",
      "Epoch 240/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2608\n",
      "Epoch 241/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2608\n",
      "Epoch 242/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2608\n",
      "Epoch 243/400\n",
      "7/7 [==============================] - 0s 670us/step - loss: 0.2608\n",
      "Epoch 244/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2608\n",
      "Epoch 245/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.2608\n",
      "Epoch 246/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2608\n",
      "Epoch 247/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2608\n",
      "Epoch 248/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2607\n",
      "Epoch 249/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2607\n",
      "Epoch 250/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2607\n",
      "Epoch 251/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2608\n",
      "Epoch 252/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2607\n",
      "Epoch 253/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2607\n",
      "Epoch 254/400\n",
      "7/7 [==============================] - 0s 830us/step - loss: 0.2607\n",
      "Epoch 255/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2607\n",
      "Epoch 256/400\n",
      "7/7 [==============================] - 0s 834us/step - loss: 0.2607\n",
      "Epoch 257/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2607\n",
      "Epoch 258/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2607\n",
      "Epoch 259/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2606\n",
      "Epoch 260/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2607\n",
      "Epoch 261/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2606\n",
      "Epoch 262/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2607\n",
      "Epoch 263/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2606\n",
      "Epoch 264/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2606\n",
      "Epoch 265/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2606\n",
      "Epoch 266/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2606\n",
      "Epoch 267/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2606\n",
      "Epoch 268/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2606\n",
      "Epoch 269/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2606\n",
      "Epoch 270/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 271/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 272/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2605\n",
      "Epoch 273/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 274/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 275/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2605\n",
      "Epoch 276/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 277/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2605\n",
      "Epoch 278/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2607\n",
      "Epoch 279/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2606\n",
      "Epoch 280/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2604\n",
      "Epoch 281/400\n",
      "7/7 [==============================] - 0s 837us/step - loss: 0.2604\n",
      "Epoch 282/400\n",
      "7/7 [==============================] - 0s 769us/step - loss: 0.2604\n",
      "Epoch 283/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 284/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 285/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2605\n",
      "Epoch 286/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 287/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2604\n",
      "Epoch 288/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 289/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2604\n",
      "Epoch 290/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2604\n",
      "Epoch 291/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2604\n",
      "Epoch 292/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2607\n",
      "Epoch 293/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2603\n",
      "Epoch 294/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2603\n",
      "Epoch 295/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2603\n",
      "Epoch 296/400\n",
      "7/7 [==============================] - 0s 762us/step - loss: 0.2603\n",
      "Epoch 297/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 298/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2602\n",
      "Epoch 299/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2603\n",
      "Epoch 300/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2604\n",
      "Epoch 301/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 670us/step - loss: 0.2604\n",
      "Epoch 302/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2602\n",
      "Epoch 303/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2604\n",
      "Epoch 304/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2604\n",
      "Epoch 305/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2604\n",
      "Epoch 306/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 307/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2605\n",
      "Epoch 308/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2603\n",
      "Epoch 309/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2603\n",
      "Epoch 310/400\n",
      "7/7 [==============================] - 0s 670us/step - loss: 0.2602\n",
      "Epoch 311/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2602\n",
      "Epoch 312/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2602\n",
      "Epoch 313/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2601\n",
      "Epoch 314/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2605\n",
      "Epoch 315/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2603\n",
      "Epoch 316/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 317/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2603\n",
      "Epoch 318/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2603\n",
      "Epoch 319/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2602\n",
      "Epoch 320/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2603\n",
      "Epoch 321/400\n",
      "7/7 [==============================] - 0s 660us/step - loss: 0.2605\n",
      "Epoch 322/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2604\n",
      "Epoch 323/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2602\n",
      "Epoch 324/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2603\n",
      "Epoch 325/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2601\n",
      "Epoch 326/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2601\n",
      "Epoch 327/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2600\n",
      "Epoch 328/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2600\n",
      "Epoch 329/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2601\n",
      "Epoch 330/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2601\n",
      "Epoch 331/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2601\n",
      "Epoch 332/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2601\n",
      "Epoch 333/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2599\n",
      "Epoch 334/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2597\n",
      "Epoch 335/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2599\n",
      "Epoch 336/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2603\n",
      "Epoch 337/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2606\n",
      "Epoch 338/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2603\n",
      "Epoch 339/400\n",
      "7/7 [==============================] - 0s 834us/step - loss: 0.2602\n",
      "Epoch 340/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2601\n",
      "Epoch 341/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2599\n",
      "Epoch 342/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2598\n",
      "Epoch 343/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2600\n",
      "Epoch 344/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2599\n",
      "Epoch 345/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2599\n",
      "Epoch 346/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2599\n",
      "Epoch 347/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2598\n",
      "Epoch 348/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2598\n",
      "Epoch 349/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2597\n",
      "Epoch 350/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2597\n",
      "Epoch 351/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2597\n",
      "Epoch 352/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2598\n",
      "Epoch 353/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2598\n",
      "Epoch 354/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2598\n",
      "Epoch 355/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2597\n",
      "Epoch 356/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2600\n",
      "Epoch 357/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2600\n",
      "Epoch 358/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2599\n",
      "Epoch 359/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2600\n",
      "Epoch 360/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2600\n",
      "Epoch 361/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2599\n",
      "Epoch 362/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2600\n",
      "Epoch 363/400\n",
      "7/7 [==============================] - 0s 830us/step - loss: 0.2597\n",
      "Epoch 364/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2597\n",
      "Epoch 365/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2598\n",
      "Epoch 366/400\n",
      "7/7 [==============================] - 0s 834us/step - loss: 0.2598\n",
      "Epoch 367/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2601\n",
      "Epoch 368/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2597\n",
      "Epoch 369/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2596\n",
      "Epoch 370/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2596\n",
      "Epoch 371/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2596\n",
      "Epoch 372/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2595\n",
      "Epoch 373/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2596\n",
      "Epoch 374/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2596\n",
      "Epoch 375/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2596\n",
      "Epoch 376/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2597\n",
      "Epoch 377/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2595\n",
      "Epoch 378/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2595\n",
      "Epoch 379/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2597\n",
      "Epoch 380/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2598\n",
      "Epoch 381/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2598\n",
      "Epoch 382/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2597\n",
      "Epoch 383/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2597\n",
      "Epoch 384/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2595\n",
      "Epoch 385/400\n",
      "7/7 [==============================] - 0s 828us/step - loss: 0.2595\n",
      "Epoch 386/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2598\n",
      "Epoch 387/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2597\n",
      "Epoch 388/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2596\n",
      "Epoch 389/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2595\n",
      "Epoch 390/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2595\n",
      "Epoch 391/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2594\n",
      "Epoch 392/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2594\n",
      "Epoch 393/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2596\n",
      "Epoch 394/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2595\n",
      "Epoch 395/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2594\n",
      "Epoch 396/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2594\n",
      "Epoch 397/400\n",
      "7/7 [==============================] - 0s 828us/step - loss: 0.2593\n",
      "Epoch 398/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2594\n",
      "Epoch 399/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2594\n",
      "Epoch 400/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2595\n",
      "Best: -0.273039 using {'optimizer': 'Adamax'}\n",
      "-0.353045 (0.048214) with: {'optimizer': 'SGD'}\n",
      "-0.285616 (0.046900) with: {'optimizer': 'RMSprop'}\n",
      "-26.171258 (2.183940) with: {'optimizer': 'Adagrad'}\n",
      "-30.467580 (2.139391) with: {'optimizer': 'Adadelta'}\n",
      "-0.275369 (0.044860) with: {'optimizer': 'Adam'}\n",
      "-0.273039 (0.034120) with: {'optimizer': 'Adamax'}\n",
      "-0.279036 (0.041574) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6] \n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "ROW_DIM = 0\n",
    "COL_DIM = 1\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped,\n",
    "                      y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers                import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "\n",
    "# Define the model.\n",
    "def create_model(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer='normal',\n",
    "                        activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=400, batch_size=20, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer   = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid  = dict(optimizer=optimizer)\n",
    "grid        = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "#################################################\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means   = grid_result.cv_results_['mean_test_score']\n",
    "stds    = grid_result.cv_results_['std_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The grid search found the best optimizer to use was Adamax. Now we can further optimize the optimizer by finding the best learning rate to use with Adamax. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.3906 - accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.2798 - accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.1699 - accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 30.0542 - accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.9457 - accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.8367 - accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.7178 - accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 29.5888 - accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 29.4499 - accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.2976 - accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.1322 - accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 28.9621 - accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 28.7745 - accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 28.5820 - accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 28.3840 - accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 28.1701 - accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 27.9478 - accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 27.7078 - accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 27.4672 - accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 27.2133 - accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 26.9469 - accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 26.6906 - accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 26.4313 - accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 26.1642 - accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 25.8798 - accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 25.5808 - accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 25.2760 - accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 24.9636 - accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 24.6367 - accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 24.2929 - accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 23.9411 - accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 23.5970 - accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 23.2564 - accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 22.9032 - accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 22.5290 - accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 22.1598 - accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 21.7858 - accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 21.4209 - accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 21.0405 - accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 20.6511 - accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2649 - accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 19.8592 - accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4463 - accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 19.0249 - accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6297 - accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2177 - accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7969 - accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3723 - accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.9437 - accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.5211 - accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0920 - accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.6630 - accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.2231 - accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 14.8121 - accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "7/7 [==============================] - 0s 881us/step - loss: 14.4244 - accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 14.0256 - accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 13.6362 - accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 13.2420 - accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8326 - accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 12.4355 - accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 12.0305 - accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 11.6244 - accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 11.2264 - accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 10.8279 - accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 10.4383 - accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 10.0483 - accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6600 - accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 9.2781 - accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8989 - accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 8.5243 - accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 8.1506 - accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7928 - accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4334 - accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0828 - accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.7380 - accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3981 - accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.0694 - accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7505 - accuracy: 0.0000e+00\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4515 - accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1564 - accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.8790 - accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6105 - accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3510 - accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.1063 - accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8638 - accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6324 - accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4103 - accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1953 - accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9878 - accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7978 - accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6095 - accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4371 - accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2731 - accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1139 - accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9670 - accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.8285 - accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.7004 - accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.5742 - accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.4600 - accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.3557 - accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.2556 - accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.1667 - accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.0819 - accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.0049 - accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9319 - accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.8649 - accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.8050 - accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.7495 - accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.7002 - accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.6132 - accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.5747 - accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.5403 - accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4819 - accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.4562 - accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.4340 - accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3974 - accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3828 - accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3554 - accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3431 - accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3330 - accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3247 - accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3176 - accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3014 - accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2965 - accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2934 - accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2866 - accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2841 - accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2818 - accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2803 - accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2782 - accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2751 - accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2742 - accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2723 - accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "7/7 [==============================] - 0s 916us/step - loss: 0.2713 - accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2705 - accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2699 - accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2693 - accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2686 - accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2684 - accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2679 - accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2678 - accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2676 - accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2674 - accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2671 - accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2671 - accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.0000e+00\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 0.2669 - accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2669 - accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2669 - accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2668 - accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2668 - accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2668 - accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2670 - accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2669 - accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2668 - accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2667 - accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2666 - accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2668 - accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2666 - accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2667 - accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2666 - accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2667 - accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "7/7 [==============================] - 0s 949us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2660 - accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2660 - accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2660 - accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2659 - accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 997us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2654 - accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2653 - accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2654 - accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2653 - accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2656 - accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2655 - accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2653 - accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2653 - accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2652 - accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2651 - accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2651 - accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2652 - accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2651 - accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2649 - accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2649 - accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2649 - accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2651 - accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2649 - accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2648 - accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2648 - accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2648 - accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2648 - accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2649 - accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2648 - accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2648 - accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2645 - accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2645 - accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2645 - accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2646 - accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2644 - accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2644 - accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2646 - accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2645 - accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2640 - accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2640 - accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2640 - accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2640 - accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2643 - accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2639 - accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2639 - accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2638 - accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2637 - accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2641 - accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2637 - accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2638 - accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2635 - accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2635 - accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2635 - accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2633 - accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2633 - accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2633 - accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2633 - accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2631 - accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2629 - accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2630 - accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2632 - accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2629 - accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2628 - accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2628 - accuracy: 0.0000e+00\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 665us/step - loss: 0.2629 - accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2627 - accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2628 - accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2628 - accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2629 - accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2629 - accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2628 - accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2627 - accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.0000e+00\n",
      "Best: -0.267650 using {'learningRate': 0.001}\n",
      "-0.267650 (0.036034) with: {'learningRate': 0.001}\n",
      "-0.295141 (0.037728) with: {'learningRate': 0.005}\n",
      "-0.307570 (0.054557) with: {'learningRate': 0.01}\n",
      "-0.789243 (0.630027) with: {'learningRate': 0.015}\n",
      "-0.562164 (0.328908) with: {'learningRate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6]\n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped,\n",
    "                      y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers                import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "def create_model(learningRate = 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer='normal',\n",
    "              activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    opt = Adamax(lr=learningRate)\n",
    "    model.compile(loss='mse', metrics=['accuracy'], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "### Grid Building Section #######################\n",
    "model = KerasRegressor(build_fn=create_model,epochs=400, batch_size=20, verbose=1)\n",
    "\n",
    "# Define the grid search parameters.\n",
    "learningRates= [0.001, 0.005, 0.01, 0.015, 0.2]\n",
    "param_grid   = dict(learningRate=learningRates)\n",
    "grid         = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means   = grid_result.cv_results_['mean_test_score']\n",
    "stds    = grid_result.cv_results_['std_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The best learning rate for Adamax turns out to be 0.001. Lets now grid search for an optimal initializer. This will help optimize the initial weights of the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 23.6640 - accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "7/7 [==============================] - 0s 761us/step - loss: 22.8534 - accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 22.0634 - accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 21.3300 - accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 20.5837 - accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 19.8789 - accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 19.1889 - accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 18.5606 - accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 17.9472 - accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "7/7 [==============================] - 0s 661us/step - loss: 17.3551 - accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 16.7929 - accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "7/7 [==============================] - 0s 661us/step - loss: 16.2327 - accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "7/7 [==============================] - 0s 900us/step - loss: 15.6901 - accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 15.1595 - accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 14.6391 - accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "7/7 [==============================] - 0s 829us/step - loss: 14.1223 - accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 13.6385 - accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "7/7 [==============================] - 0s 733us/step - loss: 13.1557 - accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 12.6811 - accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 12.2231 - accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 11.7800 - accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 11.3615 - accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 10.9578 - accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 10.5660 - accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 10.1870 - accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 9.8162 - accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "7/7 [==============================] - 0s 833us/step - loss: 9.4673 - accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 9.1212 - accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 8.7794 - accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 8.4519 - accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 8.1294 - accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 7.8089 - accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 7.4999 - accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 7.1951 - accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8955 - accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 6.6087 - accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 6.3223 - accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 6.0517 - accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 5.7921 - accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 5.5386 - accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 5.2889 - accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 5.0433 - accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.8059 - accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.5731 - accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.3549 - accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "7/7 [==============================] - 0s 854us/step - loss: 4.1460 - accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.9395 - accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.7458 - accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 3.5549 - accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.3740 - accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 3.1958 - accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "7/7 [==============================] - 0s 851us/step - loss: 3.0294 - accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "7/7 [==============================] - 0s 913us/step - loss: 2.8691 - accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 2.7162 - accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 2.5734 - accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.4326 - accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 2.3035 - accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 2.1805 - accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.0619 - accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 1.9483 - accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.8372 - accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 1.7336 - accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.6366 - accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.5441 - accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.4594 - accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.3783 - accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.3012 - accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.2289 - accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 1.1570 - accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "7/7 [==============================] - 0s 805us/step - loss: 1.0929 - accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 1.0312 - accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.9738 - accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.9209 - accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.8709 - accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.8251 - accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "7/7 [==============================] - 0s 658us/step - loss: 0.7827 - accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.7430 - accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.7042 - accuracy: 0.0000e+00\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 665us/step - loss: 0.6699 - accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.6380 - accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "7/7 [==============================] - 0s 697us/step - loss: 0.6074 - accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.5805 - accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.5532 - accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.5283 - accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.5063 - accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.4858 - accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.4657 - accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.4482 - accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.4315 - accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4173 - accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "7/7 [==============================] - 0s 829us/step - loss: 0.4047 - accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3929 - accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3818 - accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "7/7 [==============================] - 0s 791us/step - loss: 0.3724 - accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3636 - accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.3550 - accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3477 - accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3411 - accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3349 - accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3296 - accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3242 - accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3203 - accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3159 - accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3126 - accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3094 - accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.3070 - accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3049 - accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3024 - accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3007 - accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2987 - accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2971 - accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2958 - accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2948 - accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2932 - accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2922 - accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2907 - accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2901 - accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2894 - accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2891 - accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2886 - accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2881 - accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2877 - accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2873 - accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2869 - accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2863 - accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2863 - accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2858 - accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2855 - accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2854 - accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2852 - accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2850 - accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2850 - accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2849 - accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2848 - accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2848 - accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2847 - accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2846 - accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2847 - accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2845 - accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2844 - accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2844 - accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2844 - accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2844 - accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2843 - accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "7/7 [==============================] - 0s 664us/step - loss: 0.2842 - accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2842 - accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2841 - accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2841 - accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2841 - accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2841 - accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2840 - accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2839 - accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2839 - accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2839 - accuracy: 0.0000e+00\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 0.2838 - accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2838 - accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2838 - accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2837 - accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2837 - accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2837 - accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2837 - accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2837 - accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2836 - accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2835 - accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2836 - accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2834 - accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2835 - accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2833 - accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2835 - accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2834 - accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2833 - accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2833 - accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2833 - accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "7/7 [==============================] - 0s 843us/step - loss: 0.2832 - accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2832 - accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2830 - accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2831 - accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2831 - accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2830 - accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2829 - accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2829 - accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2830 - accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2828 - accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "7/7 [==============================] - 0s 718us/step - loss: 0.2828 - accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2827 - accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2827 - accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2827 - accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2826 - accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2827 - accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2825 - accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2828 - accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.2826 - accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "7/7 [==============================] - 0s 661us/step - loss: 0.2825 - accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2824 - accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2824 - accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2824 - accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2823 - accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2822 - accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "7/7 [==============================] - 0s 730us/step - loss: 0.2822 - accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2821 - accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2821 - accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2821 - accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2821 - accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2820 - accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2819 - accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2819 - accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "7/7 [==============================] - 0s 840us/step - loss: 0.2818 - accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2817 - accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2818 - accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "7/7 [==============================] - 0s 670us/step - loss: 0.2819 - accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2819 - accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2818 - accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "7/7 [==============================] - 0s 683us/step - loss: 0.2818 - accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2817 - accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2817 - accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2817 - accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "7/7 [==============================] - 0s 670us/step - loss: 0.2817 - accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2815 - accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2815 - accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2815 - accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "7/7 [==============================] - 0s 829us/step - loss: 0.2815 - accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "7/7 [==============================] - 0s 662us/step - loss: 0.2814 - accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2813 - accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2812 - accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "7/7 [==============================] - 0s 670us/step - loss: 0.2811 - accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2811 - accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.2812 - accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2811 - accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2811 - accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2810 - accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2809 - accuracy: 0.0000e+00\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "7/7 [==============================] - 0s 663us/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "7/7 [==============================] - 0s 794us/step - loss: 0.2807 - accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2807 - accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2806 - accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2805 - accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "7/7 [==============================] - 0s 661us/step - loss: 0.2805 - accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2805 - accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2804 - accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2804 - accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.2803 - accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2803 - accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2802 - accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2801 - accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2799 - accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2798 - accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2798 - accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2796 - accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2795 - accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2795 - accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2795 - accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2795 - accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2792 - accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2792 - accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2792 - accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2790 - accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2791 - accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2789 - accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2788 - accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2787 - accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "7/7 [==============================] - 0s 751us/step - loss: 0.2787 - accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2786 - accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2785 - accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2784 - accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2782 - accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2783 - accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2785 - accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2784 - accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2782 - accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2781 - accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2780 - accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2780 - accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2780 - accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2780 - accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2778 - accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2778 - accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2780 - accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2777 - accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2775 - accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2777 - accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2775 - accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2776 - accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2774 - accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2774 - accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2773 - accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2773 - accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2772 - accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2772 - accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2771 - accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2770 - accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2770 - accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2769 - accuracy: 0.0000e+00\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 997us/step - loss: 0.2769 - accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2769 - accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2769 - accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2766 - accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2764 - accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2761 - accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2764 - accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2761 - accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2760 - accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2759 - accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2759 - accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2758 - accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2759 - accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2757 - accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2757 - accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2754 - accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2754 - accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2753 - accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2754 - accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2752 - accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2748 - accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2746 - accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2747 - accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2744 - accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2745 - accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2744 - accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2744 - accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2743 - accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2743 - accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2743 - accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2742 - accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2741 - accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2741 - accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2737 - accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2737 - accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2734 - accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2735 - accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2734 - accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2736 - accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2735 - accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2735 - accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2734 - accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2733 - accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2731 - accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2730 - accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2730 - accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2730 - accuracy: 0.0000e+00\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 0.2730 - accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2729 - accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2729 - accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2728 - accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2728 - accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2727 - accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2726 - accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2725 - accuracy: 0.0000e+00\n",
      "Best: -0.246671 using {'init_mode': 'glorot_normal'}\n",
      "-0.274739 (0.032232) with: {'init_mode': 'uniform'}\n",
      "-0.339214 (0.109609) with: {'init_mode': 'lecun_uniform'}\n",
      "-0.275407 (0.039803) with: {'init_mode': 'normal'}\n",
      "-15.484890 (1.305733) with: {'init_mode': 'zero'}\n",
      "-0.246671 (0.024980) with: {'init_mode': 'glorot_normal'}\n",
      "-5.260684 (7.004468) with: {'init_mode': 'glorot_uniform'}\n",
      "-5.925112 (7.958032) with: {'init_mode': 'he_normal'}\n",
      "-0.353689 (0.036073) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6]\n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped,\n",
    "                      y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers                import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "def create_model(init_mode='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer=init_mode,\n",
    "              activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode))\n",
    "    # Use Adam optimizer with the given learning rate\n",
    "    opt = Adamax(lr=0.001)\n",
    "    model.compile(loss='mse', metrics=['accuracy'], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "### Grid Building Section #######################\n",
    "model = KerasRegressor(build_fn=create_model, epochs=400, batch_size=20, verbose=1)\n",
    "\n",
    "# Define the grid search parameters.\n",
    "init_mode  = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', \n",
    "              'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid   = dict(init_mode=init_mode)\n",
    "grid         = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means   = grid_result.cv_results_['mean_test_score']\n",
    "stds    = grid_result.cv_results_['std_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The best initializer chosen is glorot_normal. Now we can grid search for the optimal of neurons in the hidden layer of the network. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4884 - accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4875 - accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4872 - accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4865 - accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4860 - accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4834 - accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4799 - accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4703 - accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4484 - accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.3416 - accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.0958 - accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 29.6627 - accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 29.0446 - accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 28.3510 - accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 27.6329 - accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 26.8769 - accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 26.1416 - accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "7/7 [==============================] - 0s 970us/step - loss: 25.4422 - accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 24.7458 - accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 24.0541 - accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 23.3617 - accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 22.6779 - accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 21.9919 - accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 21.3036 - accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 20.6121 - accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 19.9137 - accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 19.2067 - accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 18.4950 - accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 17.7702 - accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.0617 - accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "7/7 [==============================] - 0s 992us/step - loss: 16.3827 - accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 15.6900 - accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 14.9876 - accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 14.2989 - accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 13.6133 - accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 12.9297 - accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 12.2968 - accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 11.7200 - accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 11.1505 - accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 10.5760 - accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "7/7 [==============================] - 0s 751us/step - loss: 10.0075 - accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 9.4329 - accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 8.8797 - accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 8.3512 - accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 7.8231 - accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3095 - accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 6.8078 - accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 6.3198 - accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 5.8491 - accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 5.3978 - accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 4.9476 - accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "7/7 [==============================] - 0s 992us/step - loss: 4.5182 - accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1127 - accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7260 - accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3700 - accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 3.0272 - accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 2.7193 - accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 2.4250 - accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 2.1571 - accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.9206 - accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "7/7 [==============================] - 0s 993us/step - loss: 1.6959 - accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.4946 - accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3246 - accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.1725 - accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 1.0412 - accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.9259 - accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.8239 - accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.7406 - accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.6735 - accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.6102 - accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.5589 - accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.5197 - accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.4847 - accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4592 - accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.4378 - accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4196 - accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.4058 - accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.3933 - accuracy: 0.0000e+00\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 835us/step - loss: 0.3830 - accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.3757 - accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3695 - accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3639 - accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3601 - accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3574 - accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3554 - accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3537 - accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "7/7 [==============================] - 0s 667us/step - loss: 0.3520 - accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3510 - accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3501 - accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3491 - accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3485 - accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3481 - accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3476 - accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3473 - accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3470 - accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3466 - accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3464 - accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3463 - accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3458 - accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3453 - accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3449 - accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3447 - accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3441 - accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3438 - accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3433 - accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3428 - accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3424 - accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.3419 - accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3414 - accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3410 - accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "7/7 [==============================] - 0s 993us/step - loss: 0.3406 - accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3402 - accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3399 - accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "7/7 [==============================] - 0s 826us/step - loss: 0.3395 - accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3391 - accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3388 - accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3385 - accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.3381 - accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3378 - accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3373 - accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3370 - accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3367 - accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "7/7 [==============================] - 0s 830us/step - loss: 0.3364 - accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "7/7 [==============================] - 0s 829us/step - loss: 0.3361 - accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3361 - accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3353 - accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3350 - accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3346 - accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3343 - accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3340 - accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "7/7 [==============================] - 0s 667us/step - loss: 0.3337 - accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3335 - accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3328 - accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3324 - accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.3321 - accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3317 - accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.3313 - accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "7/7 [==============================] - 0s 828us/step - loss: 0.3310 - accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3306 - accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3306 - accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3299 - accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3295 - accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "7/7 [==============================] - 0s 829us/step - loss: 0.3292 - accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3289 - accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3284 - accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3281 - accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3277 - accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3273 - accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3269 - accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3266 - accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3261 - accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3258 - accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.3254 - accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3250 - accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3247 - accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3241 - accuracy: 0.0000e+00\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 0.3238 - accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.3235 - accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3230 - accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3227 - accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3224 - accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3218 - accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.3214 - accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3212 - accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3209 - accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3206 - accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "7/7 [==============================] - 0s 817us/step - loss: 0.3203 - accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3198 - accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3193 - accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.3190 - accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3186 - accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "7/7 [==============================] - 0s 827us/step - loss: 0.3181 - accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3177 - accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3173 - accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3168 - accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3169 - accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3163 - accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3159 - accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3156 - accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3152 - accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3149 - accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3141 - accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3137 - accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3134 - accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3130 - accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3128 - accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3121 - accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3119 - accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3116 - accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3111 - accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3106 - accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3103 - accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3102 - accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3095 - accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3094 - accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3089 - accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3083 - accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3073 - accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3072 - accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3067 - accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3063 - accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3060 - accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3057 - accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3054 - accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3051 - accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3048 - accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3046 - accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3043 - accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.3040 - accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "7/7 [==============================] - 0s 868us/step - loss: 0.3035 - accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3032 - accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3029 - accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3027 - accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3024 - accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3023 - accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3025 - accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3017 - accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3008 - accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3003 - accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2996 - accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2993 - accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2988 - accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2986 - accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2977 - accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2975 - accuracy: 0.0000e+00\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 997us/step - loss: 0.2968 - accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2965 - accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2964 - accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2953 - accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2949 - accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2945 - accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2943 - accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2936 - accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2939 - accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2925 - accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2923 - accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2917 - accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2916 - accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2912 - accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2909 - accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2908 - accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2907 - accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2903 - accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2900 - accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2897 - accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2896 - accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2891 - accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2888 - accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2887 - accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2881 - accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2878 - accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2874 - accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2869 - accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2875 - accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2867 - accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2859 - accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2856 - accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2855 - accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2849 - accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2850 - accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2835 - accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2828 - accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2822 - accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2815 - accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2815 - accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2801 - accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2799 - accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2784 - accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2781 - accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2781 - accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2778 - accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2776 - accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2776 - accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2772 - accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2772 - accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2772 - accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2772 - accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2768 - accuracy: 0.0000e+00\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2766 - accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2761 - accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2759 - accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2759 - accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2756 - accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2753 - accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2751 - accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2751 - accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2750 - accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2759 - accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2754 - accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2754 - accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2742 - accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2741 - accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2738 - accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2735 - accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2734 - accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2729 - accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "7/7 [==============================] - 0s 830us/step - loss: 0.2727 - accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2723 - accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2718 - accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2716 - accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2714 - accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2711 - accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2711 - accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2706 - accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2705 - accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2703 - accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.2704 - accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2698 - accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2699 - accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2698 - accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2693 - accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2693 - accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2693 - accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2693 - accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2699 - accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2694 - accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2685 - accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2683 - accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2683 - accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "7/7 [==============================] - 0s 825us/step - loss: 0.2678 - accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2681 - accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2677 - accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2674 - accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2672 - accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2674 - accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2671 - accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2670 - accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2670 - accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2667 - accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "7/7 [==============================] - 0s 830us/step - loss: 0.2667 - accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2668 - accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2665 - accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2662 - accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2666 - accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2661 - accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2660 - accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2660 - accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2663 - accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2658 - accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2654 - accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2657 - accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "7/7 [==============================] - 0s 771us/step - loss: 0.2654 - accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2651 - accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "7/7 [==============================] - 0s 670us/step - loss: 0.2644 - accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2644 - accuracy: 0.0000e+00\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 827us/step - loss: 0.2645 - accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2642 - accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.2646 - accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.2647 - accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2652 - accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2644 - accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2638 - accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2634 - accuracy: 0.0000e+00\n",
      "Best: -0.275949 using {'neurons': 25}\n",
      "-19.525928 (13.611032) with: {'neurons': 1}\n",
      "-11.318320 (15.523265) with: {'neurons': 5}\n",
      "-9.488622 (13.081941) with: {'neurons': 10}\n",
      "-0.304886 (0.070394) with: {'neurons': 15}\n",
      "-10.298402 (14.119763) with: {'neurons': 20}\n",
      "-0.275949 (0.063924) with: {'neurons': 25}\n",
      "-10.297042 (14.120781) with: {'neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6]\n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped,\n",
    "                      y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers                import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "def create_model(neurons=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=5, kernel_initializer=\"glorot_normal\",\n",
    "              activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=\"glorot_normal\", activation='relu'))\n",
    "    # Use Adam optimizer with the given learning rate\n",
    "    opt = Adamax(lr=0.001)\n",
    "    model.compile(loss='mse', metrics=['accuracy'], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "### Grid Building Section #######################\n",
    "model = KerasRegressor(build_fn=create_model, epochs=400, batch_size=20, verbose=1)\n",
    "\n",
    "# Define the grid search parameters.\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid       = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "#################################################\n",
    "\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means   = grid_result.cv_results_['mean_test_score']\n",
    "stds    = grid_result.cv_results_['std_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 23.3923 - val_loss: 22.5992\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22.1791 - val_loss: 21.4455\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 21.0570 - val_loss: 20.3718\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 20.0052 - val_loss: 19.3237\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 18.9713 - val_loss: 18.2973\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 17.9599 - val_loss: 17.3124\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.9815 - val_loss: 16.3328\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.0071 - val_loss: 15.3712\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.0540 - val_loss: 14.4307\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 14.1215 - val_loss: 13.4938\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 13.1995 - val_loss: 12.5761\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 12.3118 - val_loss: 11.7095\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.4516 - val_loss: 10.8601\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.6186 - val_loss: 10.0306\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.8117 - val_loss: 9.2290\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.0302 - val_loss: 8.4317\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2481 - val_loss: 7.6587\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.4961 - val_loss: 6.9130\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7711 - val_loss: 6.2033\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.0932 - val_loss: 5.5248\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.4386 - val_loss: 4.9018\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.8283 - val_loss: 4.3210\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2694 - val_loss: 3.7848\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7482 - val_loss: 3.3000\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.2816 - val_loss: 2.8561\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8494 - val_loss: 2.4551\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4625 - val_loss: 2.0974\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1105 - val_loss: 1.7875\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8121 - val_loss: 1.5189\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5491 - val_loss: 1.2934\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3258 - val_loss: 1.1027\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1337 - val_loss: 0.9419\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9753 - val_loss: 0.8132\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8473 - val_loss: 0.7101\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7395 - val_loss: 0.6255\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.5544\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5765 - val_loss: 0.4991\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5183 - val_loss: 0.4569\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4706 - val_loss: 0.4251\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4354 - val_loss: 0.4014\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4061 - val_loss: 0.3850\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3853 - val_loss: 0.3738\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3707 - val_loss: 0.3666\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3596 - val_loss: 0.3615\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3496 - val_loss: 0.3584\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3434 - val_loss: 0.3566\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3387 - val_loss: 0.3555\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3355 - val_loss: 0.3548\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 0.3547\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.3551\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3250 - val_loss: 0.3566\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3238 - val_loss: 0.3575\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3235 - val_loss: 0.3586\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3224 - val_loss: 0.3590\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3222 - val_loss: 0.3601\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3216 - val_loss: 0.3612\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3215 - val_loss: 0.3621\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3212 - val_loss: 0.3626\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3210 - val_loss: 0.3622\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3209 - val_loss: 0.3628\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3206 - val_loss: 0.3620\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3204 - val_loss: 0.3612\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3202 - val_loss: 0.3605\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3201 - val_loss: 0.3600\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3200 - val_loss: 0.3590\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3197 - val_loss: 0.3585\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3196 - val_loss: 0.3583\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3195 - val_loss: 0.3583\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3192 - val_loss: 0.3576\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3190 - val_loss: 0.3576\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3188 - val_loss: 0.3575\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3186 - val_loss: 0.3582\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3182 - val_loss: 0.3586\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3179 - val_loss: 0.3587\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3177 - val_loss: 0.3588\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3174 - val_loss: 0.3591\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3174 - val_loss: 0.3602\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3170 - val_loss: 0.3602\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3169 - val_loss: 0.3608\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3167 - val_loss: 0.3610\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3165 - val_loss: 0.3610\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3162 - val_loss: 0.3607\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3160 - val_loss: 0.3607\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3159 - val_loss: 0.3607\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3157 - val_loss: 0.3610\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3156 - val_loss: 0.3602\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3151 - val_loss: 0.3603\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3151 - val_loss: 0.3601\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3147 - val_loss: 0.3595\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3149 - val_loss: 0.3583\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3142 - val_loss: 0.3593\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3141 - val_loss: 0.3595\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3140 - val_loss: 0.3582\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3136 - val_loss: 0.3580\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3133 - val_loss: 0.3562\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3131 - val_loss: 0.3559\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3129 - val_loss: 0.3557\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3127 - val_loss: 0.3555\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3125 - val_loss: 0.3560\n",
      "Neural network MSE: 0.35601962\n",
      "Neural network RMSE: 0.5966738\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn                 import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models            import Sequential\n",
    "from keras.layers            import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6]\n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "\n",
    "ROW_DIM = 0\n",
    "COL_DIM = 1\n",
    "\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped, \n",
    "         y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model.\n",
    "def create_model():\n",
    "   model = Sequential()\n",
    "   model.add(Dense(25, input_dim=5, kernel_initializer=\"glorot_normal\", \n",
    "             activation='relu'))\n",
    "   model.add(Dense(1, kernel_initializer=\"glorot_normal\", activation='relu'))\n",
    "   opt = Adamax(lr=0.001)\n",
    "   model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "   return model\n",
    "\n",
    "\n",
    "\n",
    "# Build the model.\n",
    "model   = create_model()\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model.\n",
    "predictions = model.predict(X_test)\n",
    "mse         = metrics.mean_squared_error(y_test, predictions)\n",
    "print(\"Neural network MSE: \" + str(mse))\n",
    "print(\"Neural network RMSE: \" + str(np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> After adjusting the Learning Rate, Optimizer, number of neurons, and epochs and batch size, the lowest RMSE that my model could come up with is 0.596. With some more grid searching, I am sure you could get it to drop to 0.57. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> I will try to grid search multiple parameters at once. This will take quite a long time, but hopefully the outcome will be a better RMSE than what we have </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 999us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 837us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 829us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 835us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 836us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 993us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 836us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 992us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 993us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 992us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 835us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 826us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 835us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 826us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 863us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 827us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 827us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 835us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 30.4888 - accuracy: 0.0000e+00\n",
      "Best: -0.271188 using {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-17.063365 (2.048259) with: {'activation': 'softmax', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-17.201250 (1.368062) with: {'activation': 'softmax', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'softmax', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-26.128428 (6.722042) with: {'activation': 'softmax', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-18.105127 (1.168981) with: {'activation': 'softmax', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-18.381498 (1.261494) with: {'activation': 'softmax', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-20.397437 (7.123400) with: {'activation': 'softmax', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-21.131027 (8.608421) with: {'activation': 'softmax', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-21.074437 (4.950304) with: {'activation': 'softmax', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-22.218309 (7.866483) with: {'activation': 'softmax', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'softmax', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-22.063773 (4.354278) with: {'activation': 'softmax', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-20.905870 (5.390140) with: {'activation': 'softmax', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-26.281160 (6.517831) with: {'activation': 'softmax', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'softmax', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-17.385415 (1.704963) with: {'activation': 'softmax', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-26.135052 (4.333436) with: {'activation': 'softmax', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-22.222481 (5.828741) with: {'activation': 'softmax', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-21.635269 (5.269356) with: {'activation': 'softmax', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-21.243423 (6.602475) with: {'activation': 'softmax', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-17.759581 (1.793152) with: {'activation': 'softmax', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-21.961022 (8.008967) with: {'activation': 'softmax', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-26.988761 (6.870741) with: {'activation': 'softmax', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'softmax', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-26.009779 (6.881178) with: {'activation': 'softmax', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-26.522368 (7.520643) with: {'activation': 'softmax', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-17.554100 (2.119637) with: {'activation': 'softmax', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-21.907003 (4.315909) with: {'activation': 'softmax', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-22.571293 (7.578648) with: {'activation': 'softmax', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-22.256282 (4.248214) with: {'activation': 'softmax', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-25.696663 (7.303003) with: {'activation': 'softmax', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-26.059744 (8.166826) with: {'activation': 'softmax', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-25.764541 (4.846520) with: {'activation': 'softmax', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-26.107992 (4.370821) with: {'activation': 'softmax', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-26.610667 (7.397470) with: {'activation': 'softmax', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'softmax', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-21.639926 (6.475669) with: {'activation': 'softmax', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-26.237017 (7.919058) with: {'activation': 'softmax', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-22.114264 (7.893756) with: {'activation': 'softmax', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'softmax', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-26.574807 (7.447485) with: {'activation': 'softmax', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-22.527661 (7.652922) with: {'activation': 'softmax', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-15.380618 (1.226796) with: {'activation': 'softmax', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-27.057192 (6.775542) with: {'activation': 'softmax', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-17.472388 (2.000847) with: {'activation': 'softmax', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-25.863480 (4.708540) with: {'activation': 'softmax', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-22.012234 (4.333999) with: {'activation': 'softmax', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-22.649313 (7.547423) with: {'activation': 'softmax', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-20.512238 (14.470821) with: {'activation': 'softplus', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-11.295248 (15.539678) with: {'activation': 'softplus', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-21.295421 (14.862646) with: {'activation': 'softplus', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'softplus', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-20.536581 (14.436780) with: {'activation': 'softplus', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-9.554837 (13.035116) with: {'activation': 'softplus', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-9.517454 (13.061544) with: {'activation': 'softplus', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'softplus', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-19.531668 (13.602934) with: {'activation': 'softplus', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-11.282001 (15.548971) with: {'activation': 'softplus', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-20.534289 (14.439985) with: {'activation': 'softplus', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-11.296916 (15.538401) with: {'activation': 'softplus', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-21.306121 (14.847566) with: {'activation': 'softplus', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-19.510197 (13.633229) with: {'activation': 'softplus', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-20.512796 (14.470041) with: {'activation': 'softplus', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-21.295960 (14.861886) with: {'activation': 'softplus', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-19.578050 (13.537494) with: {'activation': 'softplus', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-10.315148 (14.107773) with: {'activation': 'softplus', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-9.497488 (13.075663) with: {'activation': 'softplus', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-9.511184 (13.065988) with: {'activation': 'softplus', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-0.300266 (0.025321) with: {'activation': 'softplus', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-19.541332 (13.589300) with: {'activation': 'softplus', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-21.301404 (14.854214) with: {'activation': 'softplus', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-20.532877 (14.441960) with: {'activation': 'softplus', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-11.281851 (15.549122) with: {'activation': 'softplus', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-11.322044 (15.520924) with: {'activation': 'softplus', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-21.287496 (14.873816) with: {'activation': 'softplus', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-11.312877 (15.527131) with: {'activation': 'softplus', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-0.306761 (0.035415) with: {'activation': 'softplus', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-10.313625 (14.108847) with: {'activation': 'softplus', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-11.297058 (15.538306) with: {'activation': 'softplus', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-20.517563 (14.463374) with: {'activation': 'softplus', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-9.592232 (13.008828) with: {'activation': 'softplus', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-9.546954 (13.040718) with: {'activation': 'softplus', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'softplus', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-19.552084 (13.574129) with: {'activation': 'softplus', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-0.296776 (0.054010) with: {'activation': 'softplus', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-10.308794 (14.112376) with: {'activation': 'softplus', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-19.526463 (13.610278) with: {'activation': 'softplus', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-9.530267 (13.052489) with: {'activation': 'softplus', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-10.318646 (14.105298) with: {'activation': 'softplus', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-9.544782 (13.042342) with: {'activation': 'softplus', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-10.273018 (14.137634) with: {'activation': 'softplus', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-21.280193 (14.884109) with: {'activation': 'softplus', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-20.489368 (14.502804) with: {'activation': 'softplus', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-9.528288 (13.053968) with: {'activation': 'softplus', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-19.509862 (13.633701) with: {'activation': 'softplus', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-0.326029 (0.064571) with: {'activation': 'softplus', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-0.658617 (0.158832) with: {'activation': 'softsign', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-11.414996 (15.454904) with: {'activation': 'softsign', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-11.383114 (15.477471) with: {'activation': 'softsign', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-0.486156 (0.133064) with: {'activation': 'softsign', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-0.408791 (0.077060) with: {'activation': 'softsign', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-11.821264 (15.167630) with: {'activation': 'softsign', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-11.468756 (15.416928) with: {'activation': 'softsign', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-20.579935 (14.376159) with: {'activation': 'softsign', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-0.570082 (0.157947) with: {'activation': 'softsign', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-10.416504 (14.036186) with: {'activation': 'softsign', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-0.488805 (0.120063) with: {'activation': 'softsign', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-10.363128 (12.470750) with: {'activation': 'softsign', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-9.775823 (12.879269) with: {'activation': 'softsign', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-0.582957 (0.175764) with: {'activation': 'softsign', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-0.549324 (0.109332) with: {'activation': 'softsign', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-9.669633 (12.954197) with: {'activation': 'softsign', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-11.330763 (15.514480) with: {'activation': 'softsign', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-11.637947 (15.297596) with: {'activation': 'softsign', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-0.724443 (0.215823) with: {'activation': 'softsign', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-0.550560 (0.121292) with: {'activation': 'softsign', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-10.418492 (14.028048) with: {'activation': 'softsign', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-19.627628 (13.466530) with: {'activation': 'softsign', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-12.012796 (15.032243) with: {'activation': 'softsign', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-0.756215 (0.174991) with: {'activation': 'softsign', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-0.588602 (0.092545) with: {'activation': 'softsign', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-9.713143 (12.923523) with: {'activation': 'softsign', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-0.565121 (0.200825) with: {'activation': 'softsign', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-10.419226 (14.034243) with: {'activation': 'softsign', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-11.760371 (15.213099) with: {'activation': 'softsign', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-21.375607 (14.749637) with: {'activation': 'softsign', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-11.415733 (15.454398) with: {'activation': 'softsign', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-21.351996 (14.780850) with: {'activation': 'softsign', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-11.404127 (15.462634) with: {'activation': 'softsign', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'softsign', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-1.641221 (0.186266) with: {'activation': 'softsign', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-0.776574 (0.236701) with: {'activation': 'softsign', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-11.462738 (15.421171) with: {'activation': 'softsign', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-0.552874 (0.148552) with: {'activation': 'softsign', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-20.554619 (14.411557) with: {'activation': 'softsign', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-0.463819 (0.105473) with: {'activation': 'softsign', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-19.519629 (13.619920) with: {'activation': 'relu', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-11.299512 (15.536645) with: {'activation': 'relu', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-10.293937 (14.122950) with: {'activation': 'relu', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-0.293577 (0.083484) with: {'activation': 'relu', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-11.306164 (15.532156) with: {'activation': 'relu', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-10.310481 (14.111333) with: {'activation': 'relu', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-10.286620 (14.128058) with: {'activation': 'relu', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-20.526340 (14.451101) with: {'activation': 'relu', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-10.326661 (14.099814) with: {'activation': 'relu', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-0.334113 (0.051751) with: {'activation': 'relu', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-0.324220 (0.133463) with: {'activation': 'relu', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-19.496437 (13.652642) with: {'activation': 'relu', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-0.278275 (0.045483) with: {'activation': 'relu', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-0.290055 (0.046141) with: {'activation': 'relu', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-9.508701 (13.067753) with: {'activation': 'relu', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-0.287523 (0.095672) with: {'activation': 'relu', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-0.293041 (0.082425) with: {'activation': 'relu', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-21.325755 (14.819895) with: {'activation': 'relu', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-30.509113 (2.163287) with: {'activation': 'relu', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'relu', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'relu', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'relu', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'relu', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'relu', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-0.322042 (0.073264) with: {'activation': 'relu', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-11.302714 (15.534475) with: {'activation': 'relu', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-0.305807 (0.049062) with: {'activation': 'relu', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-0.323029 (0.120299) with: {'activation': 'relu', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-10.320850 (14.103920) with: {'activation': 'relu', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-0.310305 (0.093015) with: {'activation': 'relu', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-0.286400 (0.110470) with: {'activation': 'relu', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-11.340096 (15.508134) with: {'activation': 'relu', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-19.511721 (13.631078) with: {'activation': 'relu', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-21.306057 (14.847656) with: {'activation': 'relu', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-0.322962 (0.104584) with: {'activation': 'relu', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-9.466711 (13.097423) with: {'activation': 'relu', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-19.489295 (13.662719) with: {'activation': 'relu', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-9.519500 (13.060145) with: {'activation': 'relu', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-0.303544 (0.097014) with: {'activation': 'relu', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-11.316658 (15.524582) with: {'activation': 'relu', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-10.317016 (14.106793) with: {'activation': 'relu', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-0.333080 (0.136892) with: {'activation': 'relu', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-9.478914 (13.088800) with: {'activation': 'relu', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-11.302139 (15.535019) with: {'activation': 'relu', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-20.499169 (14.489097) with: {'activation': 'relu', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-0.321804 (0.130611) with: {'activation': 'relu', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-9.486701 (13.083289) with: {'activation': 'relu', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-9.488494 (13.082040) with: {'activation': 'relu', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-21.357784 (14.774754) with: {'activation': 'tanh', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-10.418117 (14.035071) with: {'activation': 'tanh', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-10.393874 (14.052331) with: {'activation': 'tanh', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-10.353685 (14.080549) with: {'activation': 'tanh', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-10.317143 (14.106361) with: {'activation': 'tanh', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-9.548843 (13.039269) with: {'activation': 'tanh', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-11.550143 (15.359605) with: {'activation': 'tanh', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-0.558200 (0.154993) with: {'activation': 'tanh', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-10.442620 (14.018123) with: {'activation': 'tanh', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-11.338413 (15.509071) with: {'activation': 'tanh', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-20.523221 (14.455463) with: {'activation': 'tanh', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-0.432517 (0.020420) with: {'activation': 'tanh', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-19.804763 (13.217649) with: {'activation': 'tanh', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-11.345915 (15.503759) with: {'activation': 'tanh', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-20.529730 (14.446360) with: {'activation': 'tanh', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-10.382177 (14.060409) with: {'activation': 'tanh', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-10.344656 (14.086912) with: {'activation': 'tanh', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-11.293086 (15.540642) with: {'activation': 'tanh', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-30.509113 (2.163287) with: {'activation': 'tanh', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'tanh', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'tanh', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'tanh', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'tanh', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'tanh', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-0.897990 (0.335221) with: {'activation': 'tanh', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-19.725980 (13.328791) with: {'activation': 'tanh', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-0.530187 (0.089647) with: {'activation': 'tanh', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-11.356770 (15.496079) with: {'activation': 'tanh', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-0.410890 (0.028849) with: {'activation': 'tanh', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-20.523454 (14.455137) with: {'activation': 'tanh', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-11.794467 (15.188329) with: {'activation': 'tanh', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-0.557510 (0.164417) with: {'activation': 'tanh', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-10.373213 (14.066733) with: {'activation': 'tanh', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-20.541401 (14.430040) with: {'activation': 'tanh', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-0.381219 (0.036907) with: {'activation': 'tanh', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-0.393229 (0.061574) with: {'activation': 'tanh', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-11.582112 (15.336798) with: {'activation': 'tanh', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-0.565612 (0.167157) with: {'activation': 'tanh', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-0.509815 (0.152288) with: {'activation': 'tanh', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-20.537624 (14.435321) with: {'activation': 'tanh', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-11.337293 (15.509849) with: {'activation': 'tanh', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-0.451789 (0.078732) with: {'activation': 'tanh', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-0.865555 (0.140503) with: {'activation': 'tanh', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-10.645821 (13.874412) with: {'activation': 'tanh', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-0.492591 (0.067778) with: {'activation': 'tanh', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-11.377758 (15.481292) with: {'activation': 'tanh', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-11.367195 (15.488743) with: {'activation': 'tanh', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-10.373125 (14.066869) with: {'activation': 'tanh', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-21.720597 (14.263495) with: {'activation': 'sigmoid', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'sigmoid', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-11.526640 (15.375967) with: {'activation': 'sigmoid', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-10.590192 (13.914502) with: {'activation': 'sigmoid', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-0.685045 (0.221251) with: {'activation': 'sigmoid', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-10.501546 (13.976135) with: {'activation': 'sigmoid', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-1.921887 (0.981907) with: {'activation': 'sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-20.178578 (12.690359) with: {'activation': 'sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-21.375096 (14.750356) with: {'activation': 'sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-11.518325 (15.381864) with: {'activation': 'sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-20.597978 (14.350932) with: {'activation': 'sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-19.709087 (13.352624) with: {'activation': 'sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-11.245267 (13.454750) with: {'activation': 'sigmoid', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-10.763983 (13.792654) with: {'activation': 'sigmoid', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'sigmoid', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-11.494126 (15.398959) with: {'activation': 'sigmoid', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-11.488312 (15.403069) with: {'activation': 'sigmoid', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-10.551105 (13.941299) with: {'activation': 'sigmoid', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-21.391397 (14.727383) with: {'activation': 'sigmoid', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-20.715073 (14.187236) with: {'activation': 'sigmoid', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'sigmoid', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-10.611753 (13.898861) with: {'activation': 'sigmoid', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'sigmoid', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-0.640496 (0.136664) with: {'activation': 'sigmoid', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-12.078056 (12.905493) with: {'activation': 'sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-10.697977 (13.838054) with: {'activation': 'sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-10.715166 (13.827365) with: {'activation': 'sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-20.661573 (14.262022) with: {'activation': 'sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-10.572884 (13.926481) with: {'activation': 'sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-0.601950 (0.107466) with: {'activation': 'sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-11.449177 (13.306504) with: {'activation': 'sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-10.180050 (12.599702) with: {'activation': 'sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-10.627694 (13.887889) with: {'activation': 'sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-21.387776 (14.732486) with: {'activation': 'sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-9.805001 (12.858558) with: {'activation': 'sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-21.346936 (14.790044) with: {'activation': 'sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-20.042307 (12.882564) with: {'activation': 'sigmoid', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-19.828977 (13.183491) with: {'activation': 'sigmoid', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-11.519074 (15.381311) with: {'activation': 'sigmoid', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-21.372158 (14.754497) with: {'activation': 'sigmoid', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-0.688858 (0.123174) with: {'activation': 'sigmoid', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'sigmoid', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-10.820955 (12.154145) with: {'activation': 'sigmoid', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-20.681690 (14.233901) with: {'activation': 'sigmoid', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-20.666085 (14.255714) with: {'activation': 'sigmoid', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-10.653813 (13.869513) with: {'activation': 'sigmoid', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-11.483375 (15.406571) with: {'activation': 'sigmoid', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-9.807075 (12.857794) with: {'activation': 'sigmoid', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-11.697475 (13.130416) with: {'activation': 'hard_sigmoid', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-1.219383 (0.398301) with: {'activation': 'hard_sigmoid', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-11.367603 (15.488522) with: {'activation': 'hard_sigmoid', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-19.597936 (13.509438) with: {'activation': 'hard_sigmoid', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-0.477211 (0.019190) with: {'activation': 'hard_sigmoid', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-10.413251 (14.038501) with: {'activation': 'hard_sigmoid', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-12.098979 (14.971574) with: {'activation': 'hard_sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-10.822468 (13.749162) with: {'activation': 'hard_sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-11.509127 (15.388356) with: {'activation': 'hard_sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-11.364538 (15.490604) with: {'activation': 'hard_sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'hard_sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-19.623628 (13.473190) with: {'activation': 'hard_sigmoid', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-20.365678 (12.426486) with: {'activation': 'hard_sigmoid', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-20.727131 (14.170383) with: {'activation': 'hard_sigmoid', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-11.379053 (15.480325) with: {'activation': 'hard_sigmoid', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-20.545210 (14.424714) with: {'activation': 'hard_sigmoid', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-21.314418 (14.835872) with: {'activation': 'hard_sigmoid', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-10.404248 (14.045052) with: {'activation': 'hard_sigmoid', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-11.678764 (15.268802) with: {'activation': 'hard_sigmoid', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-10.729896 (13.818067) with: {'activation': 'hard_sigmoid', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'hard_sigmoid', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-11.381054 (15.478904) with: {'activation': 'hard_sigmoid', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-21.310352 (14.841602) with: {'activation': 'hard_sigmoid', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-20.538422 (14.434206) with: {'activation': 'hard_sigmoid', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-20.620670 (14.319206) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-11.745259 (15.225115) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-20.575097 (14.382924) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-19.692228 (13.376408) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-20.554137 (14.412231) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-11.351230 (15.499996) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-21.586237 (14.452814) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-20.588387 (14.364342) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-0.481063 (0.126656) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-10.444380 (14.016768) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-9.683085 (12.945059) with: {'activation': 'hard_sigmoid', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-3.189235 (0.851027) with: {'activation': 'hard_sigmoid', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-10.991919 (13.629259) with: {'activation': 'hard_sigmoid', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-20.579531 (14.376724) with: {'activation': 'hard_sigmoid', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'hard_sigmoid', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-11.366858 (15.488951) with: {'activation': 'hard_sigmoid', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-10.470179 (13.998330) with: {'activation': 'hard_sigmoid', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-11.805721 (13.116440) with: {'activation': 'hard_sigmoid', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-9.918341 (12.780409) with: {'activation': 'hard_sigmoid', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-11.460172 (15.423125) with: {'activation': 'hard_sigmoid', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'hard_sigmoid', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-10.572421 (13.927333) with: {'activation': 'hard_sigmoid', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-19.647476 (13.439545) with: {'activation': 'hard_sigmoid', 'initializer': 'he_uniform', 'numNeurons': 35}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'uniform', 'numNeurons': 10}\n",
      "-9.485878 (13.083872) with: {'activation': 'linear', 'initializer': 'uniform', 'numNeurons': 15}\n",
      "-0.283390 (0.080479) with: {'activation': 'linear', 'initializer': 'uniform', 'numNeurons': 20}\n",
      "-0.294044 (0.064510) with: {'activation': 'linear', 'initializer': 'uniform', 'numNeurons': 25}\n",
      "-9.479569 (13.088331) with: {'activation': 'linear', 'initializer': 'uniform', 'numNeurons': 30}\n",
      "-0.291692 (0.068990) with: {'activation': 'linear', 'initializer': 'uniform', 'numNeurons': 35}\n",
      "-9.502242 (13.068207) with: {'activation': 'linear', 'initializer': 'lecun_uniform', 'numNeurons': 10}\n",
      "-9.512787 (13.064975) with: {'activation': 'linear', 'initializer': 'lecun_uniform', 'numNeurons': 15}\n",
      "-0.342351 (0.125511) with: {'activation': 'linear', 'initializer': 'lecun_uniform', 'numNeurons': 20}\n",
      "-0.323942 (0.110395) with: {'activation': 'linear', 'initializer': 'lecun_uniform', 'numNeurons': 25}\n",
      "-9.497323 (13.075807) with: {'activation': 'linear', 'initializer': 'lecun_uniform', 'numNeurons': 30}\n",
      "-10.306009 (14.114439) with: {'activation': 'linear', 'initializer': 'lecun_uniform', 'numNeurons': 35}\n",
      "-10.330461 (14.097348) with: {'activation': 'linear', 'initializer': 'normal', 'numNeurons': 10}\n",
      "-20.513475 (14.469091) with: {'activation': 'linear', 'initializer': 'normal', 'numNeurons': 15}\n",
      "-11.319136 (15.522966) with: {'activation': 'linear', 'initializer': 'normal', 'numNeurons': 20}\n",
      "-0.311082 (0.135496) with: {'activation': 'linear', 'initializer': 'normal', 'numNeurons': 25}\n",
      "-9.495922 (13.076769) with: {'activation': 'linear', 'initializer': 'normal', 'numNeurons': 30}\n",
      "-11.332622 (15.513406) with: {'activation': 'linear', 'initializer': 'normal', 'numNeurons': 35}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'zero', 'numNeurons': 10}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'zero', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'zero', 'numNeurons': 20}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'zero', 'numNeurons': 25}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'zero', 'numNeurons': 30}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'zero', 'numNeurons': 35}\n",
      "-0.298890 (0.053903) with: {'activation': 'linear', 'initializer': 'glorot_normal', 'numNeurons': 10}\n",
      "-9.491738 (13.079726) with: {'activation': 'linear', 'initializer': 'glorot_normal', 'numNeurons': 15}\n",
      "-0.354962 (0.149453) with: {'activation': 'linear', 'initializer': 'glorot_normal', 'numNeurons': 20}\n",
      "-0.314583 (0.078617) with: {'activation': 'linear', 'initializer': 'glorot_normal', 'numNeurons': 25}\n",
      "-10.324105 (14.100362) with: {'activation': 'linear', 'initializer': 'glorot_normal', 'numNeurons': 30}\n",
      "-21.355588 (14.777849) with: {'activation': 'linear', 'initializer': 'glorot_normal', 'numNeurons': 35}\n",
      "-10.261516 (14.145711) with: {'activation': 'linear', 'initializer': 'glorot_uniform', 'numNeurons': 10}\n",
      "-0.286495 (0.070707) with: {'activation': 'linear', 'initializer': 'glorot_uniform', 'numNeurons': 15}\n",
      "-30.509113 (2.163287) with: {'activation': 'linear', 'initializer': 'glorot_uniform', 'numNeurons': 20}\n",
      "-0.289885 (0.064036) with: {'activation': 'linear', 'initializer': 'glorot_uniform', 'numNeurons': 25}\n",
      "-11.330616 (15.514647) with: {'activation': 'linear', 'initializer': 'glorot_uniform', 'numNeurons': 30}\n",
      "-0.352234 (0.135935) with: {'activation': 'linear', 'initializer': 'glorot_uniform', 'numNeurons': 35}\n",
      "-11.322841 (15.520106) with: {'activation': 'linear', 'initializer': 'he_normal', 'numNeurons': 10}\n",
      "-0.323324 (0.111533) with: {'activation': 'linear', 'initializer': 'he_normal', 'numNeurons': 15}\n",
      "-10.319962 (14.104644) with: {'activation': 'linear', 'initializer': 'he_normal', 'numNeurons': 20}\n",
      "-9.478258 (13.089267) with: {'activation': 'linear', 'initializer': 'he_normal', 'numNeurons': 25}\n",
      "-0.277660 (0.065803) with: {'activation': 'linear', 'initializer': 'he_normal', 'numNeurons': 30}\n",
      "-19.507359 (13.637233) with: {'activation': 'linear', 'initializer': 'he_normal', 'numNeurons': 35}\n",
      "-10.336788 (14.093023) with: {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 10}\n",
      "-21.347892 (14.788696) with: {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 15}\n",
      "-0.271188 (0.070038) with: {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 20}\n",
      "-11.356717 (15.496347) with: {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 25}\n",
      "-0.320499 (0.121408) with: {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 30}\n",
      "-0.281047 (0.079520) with: {'activation': 'linear', 'initializer': 'he_uniform', 'numNeurons': 35}\n"
     ]
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6]\n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped,\n",
    "                      y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers                import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "def create_model(numNeurons=5, initializer='uniform', activation='softplus'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, kernel_initializer=\"glorot_normal\",\n",
    "                    input_dim=5, activation='relu'))\n",
    "\n",
    "    model.add(Dense(numNeurons, kernel_initializer=initializer,  \n",
    "              activation=activation))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer=\"glorot_normal\",  activation='relu'))\n",
    "    opt = Adamax(lr=0.001)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', metrics=['accuracy'], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Grid Building Section #######################\n",
    "# Define the parameters to try out\n",
    "params = { 'activation' : ['softmax', 'softplus', 'softsign', 'relu', 'tanh', \n",
    "                           'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "          'numNeurons':[10, 15, 20, 25, 30, 35],\n",
    "          'initializer': ['uniform', 'lecun_uniform', 'normal', 'zero', \n",
    "                       'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "          }\n",
    "\n",
    "model      = KerasRegressor(build_fn=create_model, epochs=100, batch_size=20, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, cv=3)\n",
    "#################################################\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means   = grid_result.cv_results_['mean_test_score']\n",
    "stds    = grid_result.cv_results_['std_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now we will create a neural network with the features above and see if the RMSE get's any better. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 8.6078 - val_loss: 4.3693\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7335 - val_loss: 1.6063\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4784 - val_loss: 0.6914\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7753 - val_loss: 0.5903\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6330 - val_loss: 0.6846\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.7282\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6548 - val_loss: 0.7016\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6323 - val_loss: 0.6539\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 0.6170\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.5881\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.5736\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5805 - val_loss: 0.5675\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5763 - val_loss: 0.5586\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5701 - val_loss: 0.5577\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5636 - val_loss: 0.5552\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5573 - val_loss: 0.5590\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5496 - val_loss: 0.5654\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5446 - val_loss: 0.5662\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5386 - val_loss: 0.5586\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5339 - val_loss: 0.5592\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5266 - val_loss: 0.5486\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5231 - val_loss: 0.5314\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5178 - val_loss: 0.5235\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5135 - val_loss: 0.5197\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5091 - val_loss: 0.5174\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5042 - val_loss: 0.5170\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4999 - val_loss: 0.5284\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4931 - val_loss: 0.5283\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4891 - val_loss: 0.5309\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4844 - val_loss: 0.5266\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4799 - val_loss: 0.5175\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4762 - val_loss: 0.5141\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4724 - val_loss: 0.5148\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4680 - val_loss: 0.5161\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4644 - val_loss: 0.5149\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4616 - val_loss: 0.5034\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4567 - val_loss: 0.5028\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4530 - val_loss: 0.5012\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4495 - val_loss: 0.5043\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4464 - val_loss: 0.5022\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4429 - val_loss: 0.4988\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4392 - val_loss: 0.4984\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4362 - val_loss: 0.5055\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4347 - val_loss: 0.4983\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4297 - val_loss: 0.5022\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4284 - val_loss: 0.5125\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.5122\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4228 - val_loss: 0.4964\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4175 - val_loss: 0.4809\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4155 - val_loss: 0.4719\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4136 - val_loss: 0.4669\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.4713\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4073 - val_loss: 0.4698\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4054 - val_loss: 0.4647\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4016 - val_loss: 0.4756\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4003 - val_loss: 0.4854\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3984 - val_loss: 0.4890\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3962 - val_loss: 0.4784\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3935 - val_loss: 0.4686\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3908 - val_loss: 0.4625\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3888 - val_loss: 0.4563\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3882 - val_loss: 0.4523\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3859 - val_loss: 0.4678\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3824 - val_loss: 0.4736\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3815 - val_loss: 0.4755\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3797 - val_loss: 0.4712\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3785 - val_loss: 0.4541\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3763 - val_loss: 0.4577\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3738 - val_loss: 0.4525\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3723 - val_loss: 0.4494\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3702 - val_loss: 0.4531\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3693 - val_loss: 0.4570\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3683 - val_loss: 0.4438\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3661 - val_loss: 0.4453\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3646 - val_loss: 0.4575\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3628 - val_loss: 0.4573\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3614 - val_loss: 0.4632\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3595 - val_loss: 0.4569\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3577 - val_loss: 0.4491\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3559 - val_loss: 0.4437\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3556 - val_loss: 0.4464\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3529 - val_loss: 0.4403\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3515 - val_loss: 0.4376\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3499 - val_loss: 0.4276\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3491 - val_loss: 0.4243\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3480 - val_loss: 0.4293\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3461 - val_loss: 0.4395\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3451 - val_loss: 0.4406\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3443 - val_loss: 0.4475\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3433 - val_loss: 0.4309\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3413 - val_loss: 0.4200\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3406 - val_loss: 0.4226\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3390 - val_loss: 0.4279\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3381 - val_loss: 0.4346\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3370 - val_loss: 0.4337\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3363 - val_loss: 0.4337\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3351 - val_loss: 0.4305\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3333 - val_loss: 0.4156\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3325 - val_loss: 0.4044\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3325 - val_loss: 0.4066\n",
      "Neural network MSE: 0.40662086\n",
      "Neural network RMSE: 0.6376683\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn                 import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models            import Sequential\n",
    "from keras.layers            import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "dataset = df.values\n",
    "X       = dataset[:, 1:6]\n",
    "y       = dataset[:,0] #predictor\n",
    "\n",
    "\n",
    "ROW_DIM = 0\n",
    "COL_DIM = 1\n",
    "\n",
    "\n",
    "x_arrayReshaped = X.reshape(X.shape[0], X.shape[1])\n",
    "y_arrayReshaped = y.reshape(y.shape[ROW_DIM],1)\n",
    "\n",
    "x_arrayReshaped = np.asarray(x_arrayReshaped).astype(np.float32)\n",
    "y_arrayReshaped = np.asarray(y_arrayReshaped).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_arrayReshaped, \n",
    "         y_arrayReshaped, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model.\n",
    "def create_model():\n",
    "   model = Sequential()\n",
    "   model.add(Dense(25, input_dim=5, kernel_initializer='he_uniform',activation='linear'))\n",
    "   model.add(Dense(20, kernel_initializer='he_uniform',activation='linear'))\n",
    "   model.add(Dense(1, kernel_initializer='he_uniform', activation='linear'))\n",
    "   opt = Adamax(lr=0.001)\n",
    "   model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "   return model\n",
    "\n",
    "\n",
    "\n",
    "# Build the model.\n",
    "model   = create_model()\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model.\n",
    "predictions = model.predict(X_test)\n",
    "mse         = metrics.mean_squared_error(y_test, predictions)\n",
    "print(\"Neural network MSE: \" + str(mse))\n",
    "print(\"Neural network RMSE: \" + str(np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The RMSE got worse when adding in another layer. I am sure with some more parameter tweaking you could improve that. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <u>Model Evaluation</u> </h2>\n",
    "<h3> Out of the 2 models that I tried, the neural net improved the RMSE value from the OLS model from Root Mean Squared Error: 0.6311 to 0.5987. I would say that is a decent improvement. Further improvements you could add to increase the accuracy of the model would be to create multiple neural networks and use bagging. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
